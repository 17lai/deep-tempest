k: 0
loss = 2001084.1309814458
diff_x: 2.8284271247405375
-----------
k: 1
loss = 1621084.1312263082
diff_x: 2.8167675655525137
-----------
k: 2
loss = 1282403.5993848264
diff_x: 2.795220154441271
-----------
k: 3
loss = 985530.714522564
diff_x: 2.7618802834687104
-----------
k: 4
loss = 730593.402183331
diff_x: 2.7141924107546287
-----------
k: 5
loss = 518405.144916386
diff_x: 2.6533657968393585
-----------
k: 6
loss = 346358.7943660562
diff_x: 2.5641116357615927
-----------
k: 7
loss = 211729.29059451775
diff_x: 2.4630040113932905
-----------
k: 8
loss = 114035.1425235296
diff_x: 2.3367698664648238
-----------
k: 9
loss = 49552.12834487707
diff_x: 2.1859997470423234
-----------
k: 10
loss = 13947.29764870412
diff_x: 2.0104820987736423
-----------
k: 11
loss = 2293.621987420974
diff_x: 1.811449589408647
-----------
k: 12
loss = 9101.687303778872
diff_x: 1.5917971067951786
-----------
k: 13
loss = 28627.385637550586
diff_x: 1.3560436065959065
-----------
k: 14
loss = 55254.69560319425
diff_x: 1.1100033354888679
-----------
k: 15
loss = 83894.02058120474
diff_x: 0.8602223387676302
-----------
k: 16
loss = 110325.76147595674
diff_x: 0.6133189407320158
-----------
k: 17
loss = 131430.32266735082
diff_x: 0.37539090110917267
-----------
k: 18
loss = 145275.49561645818
diff_x: 0.1516087737768489
-----------
k: 19
loss = 151066.7111553201
diff_x: 0.0539889001585674
-----------
k: 20
loss = 148991.526402972
diff_x: 0.2384074423672812
-----------
k: 21
loss = 140000.517844574
diff_x: 0.3996953293166019
-----------
k: 22
loss = 125564.4494485907
diff_x: 0.5366530972924553
-----------
k: 23
loss = 107438.00388193969
diff_x: 0.6486983286706349
-----------
k: 24
loss = 87449.35944318415
diff_x: 0.7357152846667554
-----------
k: 25
loss = 67325.75434564427
diff_x: 0.7979574213262004
-----------
k: 26
loss = 48559.18742877328
diff_x: 0.8359964405530038
-----------
k: 27
loss = 32312.957920298428
diff_x: 0.8507091574804925
-----------
k: 28
loss = 19368.048303137664
diff_x: 0.8432894626716888
-----------
k: 29
loss = 10107.367309519374
diff_x: 0.8152708443178622
-----------
k: 30
loss = 4534.814163195646
diff_x: 0.7685448923685129
-----------
k: 31
loss = 2324.72257785278
diff_x: 0.7053629428318081
-----------
k: 32
loss = 2895.4192811302287
diff_x: 0.6283116279362291
-----------
k: 33
loss = 5498.679216438797
diff_x: 0.5402583159347678
-----------
k: 34
loss = 9315.425903930569
diff_x: 0.44426841290601266
-----------
k: 35
loss = 13547.516564815805
diff_x: 0.3435019641243691
-----------
k: 36
loss = 17496.207071932957
diff_x: 0.24110060142217093
-----------
k: 37
loss = 20620.104764030923
diff_x: 0.14007707475988682
-----------
k: 38
loss = 22568.509416798403
diff_x: 0.043221937993182274
-----------
k: 39
loss = 23189.3471708838
diff_x: 0.047026911450830045
-----------
k: 40
loss = 22514.279183326133
diff_x: 0.12849121883632042
-----------
k: 41
loss = 20725.766939003453
diff_x: 0.19949402144563116
-----------
k: 42
loss = 18112.463139401618
diff_x: 0.2587341491734428
-----------
k: 43
loss = 15019.508452338663
diff_x: 0.30533713212933616
-----------
k: 44
loss = 11800.017564892283
diff_x: 0.33884544698999697
-----------
k: 45
loss = 8772.905266547976
diff_x: 0.35920469696848856
-----------
k: 46
loss = 6190.7601192028615
diff_x: 0.3667435196568811
-----------
k: 47
loss = 4220.005358664183
diff_x: 0.36214703759769123
-----------
k: 48
loss = 2933.858483299524
diff_x: 0.3464231238401375
-----------
k: 49
loss = 2317.2100888061577
diff_x: 0.3208607772823799
-----------
k: 50
loss = 2281.3220037928013
diff_x: 0.286980403508085
-----------
k: 51
loss = 2685.3130563573122
diff_x: 0.24647670756776402
-----------
k: 52
loss = 3360.99019364761
diff_x: 0.20115594297421413
-----------
k: 53
loss = 4137.527801876207
diff_x: 0.15287016873326173
-----------
k: 54
loss = 4862.951993578665
diff_x: 0.10345179286912082
-----------
k: 55
loss = 5420.1400863792
diff_x: 0.0546525638437729
-----------
k: 56
loss = 5736.053382883529
diff_x: 0.00813162604071266
-----------
k: 57
loss = 5783.951020721566
diff_x: 0.03487144360935502
-----------
k: 58
loss = 5579.293569101024
diff_x: 0.07293207038821058
-----------
k: 59
loss = 5170.77464830897
diff_x: 0.10519291894637237
-----------
k: 60
loss = 4628.361711944392
diff_x: 0.1309664326468753
-----------
k: 61
loss = 4030.3590148824214
diff_x: 0.14984282362759455
-----------
k: 62
loss = 3451.348897092008
diff_x: 0.16168378000860187
-----------
k: 63
loss = 2952.4996798493485
diff_x: 0.16661006751475768
-----------
k: 64
loss = 2575.1889564679477
diff_x: 0.16498134390293204
-----------
k: 65
loss = 2338.328525875751
diff_x: 0.15736887048814802
-----------
k: 66
loss = 2239.2130888316965
diff_x: 0.144522153816481
-----------
k: 67
loss = 2257.2600100434765
diff_x: 0.12733078805109357
-----------
k: 68
loss = 2359.694402100655
diff_x: 0.10678299445613976
-----------
k: 69
loss = 2508.0940448275883
diff_x: 0.08392254520351203
-----------
k: 70
loss = 2664.728252948579
diff_x: 0.05980590614616194
-----------
k: 71
loss = 2797.8320800011215
diff_x: 0.035461781014877784
-----------
k: 72
loss = 2885.186016626767
diff_x: 0.01186172125435626
-----------
k: 73
loss = 2915.7524251020263
diff_x: 0.010209038055962091
-----------
k: 74
loss = 2889.4137537032866
diff_x: 0.02988241336251951
-----------
k: 75
loss = 2815.139593774231
diff_x: 0.046649712154425836
-----------
k: 76
loss = 2708.09363965559
diff_x: 0.06006795248410257
-----------
k: 77
loss = 2586.274737871839
diff_x: 0.06987061166628011
-----------
k: 78
loss = 2467.26858033023
diff_x: 0.0759567435372865
-----------
k: 79
loss = 2365.583282060824
diff_x: 0.07838293983974198
-----------
k: 80
loss = 2290.893231308427
diff_x: 0.07735006710523662
-----------
k: 81
loss = 2247.300421233418
diff_x: 0.0731851263026221
-----------
k: 82
loss = 2233.595537286231
diff_x: 0.06631914806430353
-----------
k: 83
loss = 2244.3042593631467
diff_x: 0.05726221402631386
-----------
k: 84
loss = 2271.2401326787767
diff_x: 0.04657678895575608
-----------
k: 85
loss = 2305.238782027672
diff_x: 0.03485060117604882
-----------
k: 86
loss = 2337.7696277894497
diff_x: 0.02267041362372809
-----------
k: 87
loss = 2362.186542158091
diff_x: 0.0105993712156935
-----------
k: 88
loss = 2374.4728292524
diff_x: 0.0009927081793204115
-----------
k: 89
loss = 2373.4394230597773
diff_x: 0.0112777412917346
-----------
k: 90
loss = 2360.4301820642086
diff_x: 0.020242804198964647
-----------
k: 91
loss = 2338.6603730147995
diff_x: 0.02750984019267303
-----------
k: 92
loss = 2312.355316591265
diff_x: 0.03289906691234583
-----------
k: 93
loss = 2285.863489725208
diff_x: 0.036329272954239
-----------
k: 94
loss = 2262.895766188319
diff_x: 0.03781283955751469
-----------
k: 95
loss = 2245.998004572233
diff_x: 0.03744808602518159
-----------
k: 96
loss = 2236.3084422518205
diff_x: 0.03540847420064008
-----------
k: 97
loss = 2233.5953089531163
diff_x: 0.03192923376358441
-----------
k: 98
loss = 2236.5232278154544
diff_x: 0.027292147918056134
-----------
k: 99
loss = 2243.0659329887844
diff_x: 0.0218093048485909
-----------
k: 100
loss = 2250.97059256597
diff_x: 0.015806656577604918
-----------
k: 101
loss = 2258.1849373061
diff_x: 0.009608383829224604
-----------
k: 102
loss = 2263.178777258524
diff_x: 0.0035260034718189916
-----------
k: 103
loss = 2265.1206725317707
diff_x: 0.0022095889853630288
-----------
k: 104
loss = 2263.902116583413
diff_x: 0.007277112541150232
-----------
k: 105
loss = 2260.0296895151937
diff_x: 0.011546179050613043
-----------
k: 106
loss = 2254.4258081966263
diff_x: 0.01487282292620576
-----------
k: 107
loss = 2248.188547676504
diff_x: 0.017178180800264956
-----------
k: 108
loss = 2242.3603249542825
diff_x: 0.01843935691486461
-----------
k: 109
loss = 2237.745724367522
diff_x: 0.01868571071167318
-----------
k: 110
loss = 2234.8034422638716
diff_x: 0.017993311045795147
-----------
k: 111
loss = 2233.61987546796
diff_x: 0.016477613003210774
-----------
k: 112
loss = 2233.955768100557
diff_x: 0.014284783415291945
-----------
k: 113
loss = 2235.34530153927
diff_x: 0.011582182431773426
-----------
k: 114
loss = 2237.220650373546
diff_x: 0.008548542942724054
-----------
k: 115
loss = 2239.034644356463
diff_x: 0.005364477545995292
-----------
k: 116
loss = 2240.358932881131
diff_x: 0.002205266388912383
-----------
k: 117
loss = 2240.9432747287537
diff_x: 0.0008058600072244424
-----------
k: 118
loss = 2240.7312027693624
diff_x: 0.0034607624246560643
-----------
k: 119
loss = 2239.8363177332717
diff_x: 0.005706689139545369
-----------
k: 120
loss = 2238.490243544022
diff_x: 0.007453815138347889
-----------
k: 121
loss = 2236.976886933079
diff_x: 0.008655726334374947
-----------
k: 122
loss = 2235.567887680677
diff_x: 0.009298364947190286
-----------
k: 123
loss = 2234.4714968813637
diff_x: 0.009397729011432241
-----------
k: 124
loss = 2233.8025361578093
diff_x: 0.008996572541574049
-----------
k: 125
loss = 2233.575755748499
diff_x: 0.00816003735573051
-----------
k: 126
loss = 2233.719974486109
diff_x: 0.0069704772595039766
-----------
k: 127
loss = 2234.10674811128
diff_x: 0.005521797218902002
-----------
k: 128
loss = 2234.585482497565
diff_x: 0.0039136607015558735
-----------
k: 129
loss = 2235.0169621268724
diff_x: 0.0022460529480644938
-----------
k: 130
loss = 2235.2988960923876
diff_x: 0.0006181381719957488
-----------
k: 131
loss = 2235.379723415218
diff_x: 0.0009128216105688678
-----------
k: 132
loss = 2235.2598834370074
diff_x: 0.0022354595565990546
-----------
k: 133
loss = 2234.982402623812
diff_x: 0.003316598200407627
-----------
k: 134
loss = 2234.6164960352576
diff_x: 0.0041170364424267724
-----------
k: 135
loss = 2234.238684216697
diff_x: 0.004617956085065191
-----------
k: 136
loss = 2233.9156872468334
diff_x: 0.00481863215740758
-----------
k: 137
loss = 2233.692290519306
diff_x: 0.00473484040234857
-----------
k: 138
loss = 2233.5858302984548
diff_x: 0.004396614039827527
-----------
k: 139
loss = 2233.587313663901
diff_x: 0.0038454223471836775
-----------
k: 140
loss = 2233.6678164419723
diff_x: 0.00313095456020458
-----------
k: 141
loss = 2233.787935029842
diff_x: 0.0023077223824009415
-----------
k: 142
loss = 2233.9078030163987
diff_x: 0.0014317459554890088
-----------
k: 143
loss = 2233.995480042646
diff_x: 0.0005583319369229099
-----------
k: 144
loss = 2234.032226796047
diff_x: 0.0002775339029613652
-----------
k: 145
loss = 2234.014082848943
diff_x: 0.0010052836220590619
-----------
k: 146
loss = 2233.9500419870396
diff_x: 0.0016117032891082325
-----------
k: 147
loss = 2233.8577914862467
diff_x: 0.0020695329440768733
-----------
k: 148
loss = 2233.7583383298324
diff_x: 0.0023656638941540833
-----------
k: 149
loss = 2233.670861550646
diff_x: 0.002497585750527189
-----------
k: 150
loss = 2233.608857105249
diff_x: 0.0024724771960013374
-----------
k: 151
loss = 2233.5781849566147
diff_x: 0.0023059556295247
-----------
k: 152
loss = 2233.5771152240804
diff_x: 0.0020204664173644705
-----------
k: 153
loss = 2233.598021036985
diff_x: 0.001643416987112033
-----------
k: 154
loss = 2233.630067057681
diff_x: 0.0012051872926930076
-----------
k: 155
loss = 2233.6621350165483
diff_x: 0.0007371884569824976
-----------
k: 156
loss = 2233.685303503491
diff_x: 0.0002707509558246226
-----------
k: 157
loss = 2233.6944122796185
diff_x: 0.00017567621856781152
-----------
k: 158
loss = 2233.688522447472
diff_x: 0.00056150609575593
-----------
k: 159
loss = 2233.670359942126
diff_x: 0.0008795778728702044
-----------
k: 160
loss = 2233.6450407327916
diff_x: 0.001115247108746923
-----------
k: 161
loss = 2233.6184856885125
diff_x: 0.0012617021672709967
-----------
k: 162
loss = 2233.5959334157274
diff_x: 0.0013181972861265904
-----------
k: 163
loss = 2233.5808682853676
diff_x: 0.0012894875452941303
-----------
k: 164
loss = 2233.574533706843
diff_x: 0.0011850596300576706
-----------
k: 165
loss = 2233.5760397523154
diff_x: 0.0010181553319106547
-----------
k: 166
loss = 2233.582938068088
diff_x: 0.0008046549968167297
-----------
k: 167
loss = 2233.592052394334
diff_x: 0.0005619064289487711
-----------
k: 168
loss = 2233.6003307074325
diff_x: 0.00030764224694062545
-----------
k: 169
loss = 2233.6055198454587
diff_x: 6.123282455615651e-05
-----------
k: 170
loss = 2233.606538108563
diff_x: 0.00017368945658752396
-----------
k: 171
loss = 2233.60351207186
diff_x: 0.00037020986248000417
-----------
k: 172
loss = 2233.597527169449
diff_x: 0.0005255757268844778
-----------
k: 173
loss = 2233.5901994913474
diff_x: 0.0006334728783265771
-----------
k: 174
loss = 2233.5831994723785
diff_x: 0.0006914287907699262
-----------
k: 175
loss = 2233.577847067727
diff_x: 0.0007003568234264089
-----------
k: 176
loss = 2233.5748608625413
diff_x: 0.0006641773459809829
-----------
k: 177
loss = 2233.574293351859
diff_x: 0.0005893075128417587
-----------
k: 178
loss = 2233.575635293491
diff_x: 0.0004840430662692058
-----------
k: 179
loss = 2233.5780350428477
diff_x: 0.0003578792605061351
-----------
k: 180
loss = 2233.5805608094106
diff_x: 0.00022083656265738918
-----------
k: 181
loss = 2233.582435925564
diff_x: 8.308808074125716e-05
-----------
k: 182
loss = 2233.5831956361135
diff_x: 5.011016750886945e-05
-----------
k: 183
loss = 2233.582741509278
diff_x: 0.00016402718408666832
-----------
k: 184
loss = 2233.581298218016
diff_x: 0.000257424726333403
-----------
k: 185
loss = 2233.579300103067
diff_x: 0.0003253603735888866
-----------
k: 186
loss = 2233.577247156305
diff_x: 0.0003656939615669578
-----------
k: 187
loss = 2233.5755706473374
diff_x: 0.0003783204127890519
-----------
k: 188
loss = 2233.574539359678
diff_x: 0.0003649596119673955
-----------
k: 189
loss = 2233.5742221935643
diff_x: 0.0003288791188956381
-----------
k: 190
loss = 2233.5745064249127
diff_x: 0.0002745456955735564
-----------
k: 191
loss = 2233.57515741149
diff_x: 0.00020723164148817784
-----------
k: 192
loss = 2233.575897813708
diff_x: 0.00013261340470096657
-----------
k: 193
loss = 2233.576483376444
diff_x: 5.6489780635645e-05
-----------
k: 194
loss = 2233.576757127988
diff_x: 1.8515400311594577e-05
-----------
k: 195
loss = 2233.5766723278066
diff_x: 8.209863401529869e-05
-----------
k: 196
loss = 2233.576283923727
diff_x: 0.0001351573351433492
-----------
k: 197
loss = 2233.575716161113
diff_x: 0.00017416856393507723
-----------
k: 198
loss = 2233.5751186199213
diff_x: 0.0001977505573784813
-----------
k: 199
loss = 2233.5746237299763
diff_x: 0.00020572635391472325
-----------
k: 200
loss = 2233.5743161858304
diff_x: 0.00019899584484605278
-----------
k: 201
loss = 2233.574219882875
diff_x: 0.00017937533599670944
-----------
k: 202
loss = 2233.574302599701
diff_x: 0.00014939384173658494
-----------
k: 203
loss = 2233.574494120565
diff_x: 0.00011206125409493777
-----------
k: 204
loss = 2233.5747108269675
diff_x: 7.063221703043807e-05
-----------
k: 205
loss = 2233.574879350074
diff_x: 2.8461719621879082e-05
-----------
k: 206
loss = 2233.5749534010783
diff_x: 1.296879931935262e-05
-----------
k: 207
loss = 2233.574920663908
diff_x: 4.798988446922613e-05
-----------
k: 208
loss = 2233.5747997259077
diff_x: 7.681118049375476e-05
-----------
k: 209
loss = 2233.574629589626
diff_x: 9.759595560986338e-05
-----------
k: 210
loss = 2233.5744557807925
diff_x: 0.00010961410131139991
-----------
k: 211
loss = 2233.574317249954
diff_x: 0.00011283447968673029
-----------
k: 212
loss = 2233.5742373293506
diff_x: 0.00010784684787276544
-----------
k: 213
loss = 2233.5742203846926
diff_x: 9.576295053731185e-05
-----------
k: 214
loss = 2233.5742540315005
diff_x: 7.809261652903476e-05
-----------
k: 215
loss = 2233.5743153540047
diff_x: 5.660483943062835e-05
-----------
k: 216
loss = 2233.574378787921
diff_x: 3.319162134926094e-05
-----------
k: 217
loss = 2233.5744232989487
diff_x: 9.880513263635346e-06
-----------
k: 218
loss = 2233.5744370872494
diff_x: 1.2755712203465473e-05
-----------
k: 219
loss = 2233.5744190101905
diff_x: 3.1592535649001484e-05
-----------
k: 220
loss = 2233.57437692537
diff_x: 4.64925184945857e-05
-----------
k: 221
loss = 2233.574323938052
diff_x: 5.665710907280868e-05
-----------
k: 222
loss = 2233.5742739228804
diff_x: 6.178577702193607e-05
-----------
k: 223
loss = 2233.5742376439966
diff_x: 6.197569148539968e-05
-----------
k: 224
loss = 2233.574220406306
diff_x: 5.767258122802241e-05
-----------
k: 225
loss = 2233.5742215971004
diff_x: 4.9606567411499695e-05
-----------
k: 226
loss = 2233.5742359064734
diff_x: 3.8714595570826945e-05
-----------
k: 227
loss = 2233.574255599726
diff_x: 2.6056929477224004e-05
-----------
k: 228
loss = 2233.57427304063
diff_x: 1.274758001512903e-05
-----------
k: 229
loss = 2233.574282736815
diff_x: 1.6193400329345995e-06
-----------
k: 230
loss = 2233.574282435925
diff_x: 1.2196492670422696e-05
-----------
k: 231
loss = 2233.5742731420814
diff_x: 2.1874048491062996e-05
-----------
k: 232
loss = 2233.574258239528
diff_x: 2.904347514275022e-05
-----------
k: 233
loss = 2233.574242121689
diff_x: 3.338971218403138e-05
-----------
k: 234
loss = 2233.574228789583
diff_x: 3.485131782860535e-05
-----------
k: 235
loss = 2233.5742208105544
diff_x: 3.3588529704248174e-05
-----------
k: 236
loss = 2233.5742188605004
diff_x: 2.9949707924639852e-05
-----------
k: 237
loss = 2233.5742218725095
diff_x: 2.442852807442946e-05
-----------
k: 238
loss = 2233.574227643057
diff_x: 1.761516606550364e-05
-----------
k: 239
loss = 2233.574233646156
diff_x: 1.0148651042259601e-05
-----------
k: 240
loss = 2233.5742377918928
diff_x: 2.7450990102313486e-06
-----------
k: 241
loss = 2233.574238927593
diff_x: 4.52094062072673e-06
-----------
k: 242
loss = 2233.574236987189
diff_x: 1.0458162655908936e-05
-----------
k: 243
loss = 2233.5742328094143
diff_x: 1.5075871388396444e-05
-----------
k: 244
loss = 2233.574227734722
diff_x: 1.8115817840120996e-05
-----------
k: 245
loss = 2233.574223133693
diff_x: 1.9490795306112015e-05
-----------
k: 246
loss = 2233.574220012108
diff_x: 1.925117054069727e-05
-----------
k: 247
loss = 2233.5742187906467
diff_x: 1.756632331605271e-05
-----------
k: 248
loss = 2233.5742192904754
diff_x: 1.4700712887788907e-05
-----------
k: 249
loss = 2233.574220892079
diff_x: 1.0985491383263554e-05
-----------
k: 250
loss = 2233.574222791183
diff_x: 6.789197425634295e-06
-----------
k: 251
loss = 2233.5742242613715
diff_x: 2.5073717649162707e-06
-----------
k: 252
loss = 2233.574224847083
diff_x: 1.7474764471060365e-06
-----------
k: 253
loss = 2233.574224444035
diff_x: 5.258602919707684e-06
-----------
k: 254
loss = 2233.5742232640705
diff_x: 8.073309939033657e-06
-----------
k: 255
loss = 2233.5742217151706
diff_x: 9.996791503683825e-06
-----------
k: 256
loss = 2233.5742202464216
diff_x: 1.0959122078144492e-05
-----------
k: 257
loss = 2233.5742192090615
diff_x: 1.0974630803296496e-05
-----------
k: 258
loss = 2233.574218771044
diff_x: 1.013085586680915e-05
-----------
k: 259
loss = 2233.5742189004095
diff_x: 8.574753142795688e-06
-----------
k: 260
loss = 2233.5742194100467
diff_x: 6.495987678211396e-06
-----------
k: 261
loss = 2233.574220039839
diff_x: 4.10928883257699e-06
-----------
k: 262
loss = 2233.57422054551
diff_x: 1.6455405831955483e-06
-----------
k: 263
loss = 2233.574220766943
diff_x: 8.356738183508978e-07
-----------

Termino!
lambda vale: 50
lr vale: 0.1
x optimo vale:
tensor([-9.6484e-07, -9.6165e-07, -9.6340e-07, -9.6020e-07, -9.6105e-07,
        -9.7361e-07, -9.8139e-07, -1.0031e-06, -9.8908e-07, -9.6803e-07,
        -9.8318e-07, -9.9024e-07, -9.9286e-07, -9.8573e-07, -9.7983e-07],
       dtype=torch.float64)
la diferencia entre y e y_pred = T(x_optimo) vale:
tensor([ 1.1449e-05-1.0786e-05j, -2.6068e-04+1.8525e-04j,
        -1.2926e-03+9.6212e-04j, -1.2113e-03+1.0671e-03j,
         1.0892e-02-8.0175e-03j, -1.1477e-02+8.3840e-03j,
         2.7640e-03-2.0646e-03j, -3.0615e-02+2.3235e-02j,
         5.5863e-02-3.7159e-02j,  7.7260e-01-5.7068e-01j,
        -1.1989e+00+8.8374e-01j,  2.7838e+00-1.9841e+00j,
        -1.1318e+00+7.3575e-01j, -2.4730e-01+1.9082e-01j,
         1.3689e+00-9.2478e-01j], grad_fn=<SliceBackward0>)
y vale:
tensor([ 1.6615e-03-1.2559e-03j, -6.8127e-04+2.5047e-04j,
        -3.0913e-02+2.2218e-02j, -1.2508e-01+9.3963e-02j,
        -4.1300e-02+5.1713e-02j, -1.2260e+00+8.5510e-01j,
         6.8436e-01-4.4347e-01j, -1.2458e+00+8.7039e-01j,
         7.3784e-01-4.7875e-01j, -4.3122e-01+2.6832e-01j,
        -4.7444e-01+4.1010e-01j,  1.5764e+00-1.1486e+00j,
        -1.2146e+00+8.4077e-01j, -8.0890e-02+1.0369e-01j,
         1.5434e-01-7.8065e-02j], grad_fn=<SliceBackward0>)
y_pred vale:
tensor([ 1.6500e-03-1.2451e-03j, -4.2059e-04+6.5213e-05j,
        -2.9621e-02+2.1256e-02j, -1.2387e-01+9.2896e-02j,
        -5.2191e-02+5.9731e-02j, -1.2146e+00+8.4671e-01j,
         6.8159e-01-4.4140e-01j, -1.2151e+00+8.4715e-01j,
         6.8197e-01-4.4159e-01j, -1.2038e+00+8.3900e-01j,
         7.2450e-01-4.7364e-01j, -1.2074e+00+8.3543e-01j,
        -8.2829e-02+1.0502e-01j,  1.6641e-01-8.7125e-02j,
        -1.2146e+00+8.4671e-01j], grad_fn=<SliceBackward0>)
