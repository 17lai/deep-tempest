k: 0
loss = 81084.13098144533
diff_x: 2.828427124604764
-----------
k: 1
loss = 65884.13122630602
diff_x: 2.8167675673663584
-----------
k: 2
loss = 52336.909709982545
diff_x: 2.7952201694538217
-----------
k: 3
loss = 40461.98581935013
diff_x: 2.761880911505887
-----------
k: 4
loss = 30287.970888314958
diff_x: 2.691781878867296
-----------
k: 5
loss = 23067.60728761932
diff_x: 2.691414535883569
-----------
k: 6
loss = 16608.17611717187
diff_x: 2.440212573687311
-----------
k: 7
loss = 11074.054205323706
diff_x: 2.402862809762418
-----------
k: 8
loss = 6952.515259586273
diff_x: 2.282977726504867
-----------
k: 9
loss = 4345.248769712076
diff_x: 2.1398247607658716
-----------
k: 10
loss = 2847.7828413173725
diff_x: 1.9735383132276183
-----------
k: 11
loss = 2277.4309832625886
diff_x: 1.7852882325986565
-----------
k: 12
loss = 2431.4835943953976
diff_x: 1.5776711918253765
-----------
k: 13
loss = 3097.095538868065
diff_x: 1.354697848528198
-----------
k: 14
loss = 4064.7135075166498
diff_x: 1.1215411703284797
-----------
k: 15
loss = 5142.194186385192
diff_x: 0.884094295604887
-----------
k: 16
loss = 6167.269118611575
diff_x: 0.6484594539377746
-----------
k: 17
loss = 7016.352216311016
diff_x: 0.42057938108378196
-----------
k: 18
loss = 7608.547335145747
diff_x: 0.20683190776346375
-----------
k: 19
loss = 7904.848403581369
diff_x: 0.04864914775343778
-----------
k: 20
loss = 7903.425095764305
diff_x: 0.18750093135614926
-----------
k: 21
loss = 7632.331000264918
diff_x: 0.34480407093488796
-----------
k: 22
loss = 7141.014303925837
diff_x: 0.4815096466415598
-----------
k: 23
loss = 6491.751519182006
diff_x: 0.5953833195108909
-----------
k: 24
loss = 5751.769516777034
diff_x: 0.6858346319250105
-----------
k: 25
loss = 4986.52704980015
diff_x: 0.7528540597330368
-----------
k: 26
loss = 4254.360729133827
diff_x: 0.7968143856584011
-----------
k: 27
loss = 3602.5970446378474
diff_x: 0.8184125368244095
-----------
k: 28
loss = 3065.103653121256
diff_x: 0.8186593999143045
-----------
k: 29
loss = 2661.25353052522
diff_x: 0.7988891427073485
-----------
k: 30
loss = 2396.18760852974
diff_x: 0.7607711917813877
-----------
k: 31
loss = 2262.2389691941694
diff_x: 0.7063120863711513
-----------
k: 32
loss = 2241.316921610179
diff_x: 0.6378380240344994
-----------
k: 33
loss = 2307.9697782315047
diff_x: 0.5579534711023217
-----------
k: 34
loss = 2432.7847299658342
diff_x: 0.4694768350543088
-----------
k: 35
loss = 2585.796375239802
diff_x: 0.3753611292209774
-----------
k: 36
loss = 2739.546378835767
diff_x: 0.2786191923187059
-----------
k: 37
loss = 2871.4550312980687
diff_x: 0.1823206065684134
-----------
k: 38
loss = 2965.4337947921917
diff_x: 0.09016658483635537
-----------
k: 39
loss = 3012.5524964655096
diff_x: 0.026438395787739648
-----------
k: 40
loss = 3010.854539223793
diff_x: 0.08827682511387913
-----------
k: 41
loss = 2964.4602088444863
diff_x: 0.15890586920233402
-----------
k: 42
loss = 2882.132945410831
diff_x: 0.2202130107474705
-----------
k: 43
loss = 2775.5707350434623
diff_x: 0.27031439731344614
-----------
k: 44
loss = 2657.624932289051
diff_x: 0.30840852902258076
-----------
k: 45
loss = 2540.668599600862
diff_x: 0.33419888208376486
-----------
k: 46
loss = 2435.2389847780373
diff_x: 0.34779059787052763
-----------
k: 47
loss = 2349.1038135946606
diff_x: 0.34964639055481406
-----------
k: 48
loss = 2286.7806967676056
diff_x: 0.3405508020618028
-----------
k: 49
loss = 2249.483317621783
diff_x: 0.3215722012058039
-----------
k: 50
loss = 2235.458475919102
diff_x: 0.29401964763800176
-----------
k: 51
loss = 2240.638849491519
diff_x: 0.25939446506558655
-----------
k: 52
loss = 2259.4605514951577
diff_x: 0.21933855266484803
-----------
k: 53
loss = 2285.7576450359693
diff_x: 0.1755849716838483
-----------
k: 54
loss = 2313.5949578831646
diff_x: 0.12992718122456418
-----------
k: 55
loss = 2337.9553779817043
diff_x: 0.08428032865986365
-----------
k: 56
loss = 2355.2080798983366
diff_x: 0.04146375817970301
-----------
k: 57
loss = 2363.3381030280866
diff_x: 0.019781203955584484
-----------
k: 58
loss = 2361.9355812971858
diff_x: 0.048393203419741716
-----------
k: 59
loss = 2351.9829738597205
diff_x: 0.08071913070300521
-----------
k: 60
loss = 2335.496452861953
diff_x: 0.10841493590223662
-----------
k: 61
loss = 2315.089522635053
diff_x: 0.13022678527833306
-----------
k: 62
loss = 2293.5241506425546
diff_x: 0.1456977338320044
-----------
k: 63
loss = 2273.3166067319517
diff_x: 0.1547258640145962
-----------
k: 64
loss = 2256.4331378033
diff_x: 0.15747436916280477
-----------
k: 65
loss = 2244.108900855232
diff_x: 0.15433030078518165
-----------
k: 66
loss = 2236.793634871701
diff_x: 0.14587091819774792
-----------
k: 67
loss = 2234.2130500202743
diff_x: 0.13282975099132946
-----------
k: 68
loss = 2235.520402423844
diff_x: 0.11606161418316614
-----------
k: 69
loss = 2239.503993317284
diff_x: 0.09650886237634865
-----------
k: 70
loss = 2244.814174461533
diff_x: 0.07517593873935358
-----------
k: 71
loss = 2250.1716934614146
diff_x: 0.053138185254222814
-----------
k: 72
loss = 2254.53660244749
diff_x: 0.031734565409810477
-----------
k: 73
loss = 2257.2167520623275
diff_x: 0.014575297048068444
-----------
k: 74
loss = 2257.906044798386
diff_x: 0.01754956361755975
-----------
k: 75
loss = 2256.6633671481804
diff_x: 0.03255630645310159
-----------
k: 76
loss = 2253.841254952886
diff_x: 0.046709456675353596
-----------
k: 77
loss = 2249.9830839302444
diff_x: 0.05817524908528539
-----------
k: 78
loss = 2245.7087764563435
diff_x: 0.06647232785639648
-----------
k: 79
loss = 2241.607236433972
diff_x: 0.07145577737804053
-----------
k: 80
loss = 2238.1522921456776
diff_x: 0.07317079343282139
-----------
k: 81
loss = 2235.649988292764
diff_x: 0.07180772970361148
-----------
k: 82
loss = 2234.215534936689
diff_x: 0.06767530315861096
-----------
k: 83
loss = 2233.7896004117883
diff_x: 0.06117735067158612
-----------
k: 84
loss = 2234.175210041338
diff_x: 0.05279078886415236
-----------
k: 85
loss = 2235.0908303085525
diff_x: 0.043046736409640275
-----------
k: 86
loss = 2236.228010659076
diff_x: 0.03252326995304373
-----------
k: 87
loss = 2237.303849859195
diff_x: 0.021887271613181717
-----------
k: 88
loss = 2238.100857138776
diff_x: 0.012238091827678703
-----------
k: 89
loss = 2238.489909249575
diff_x: 0.007712967003820692
-----------
k: 90
loss = 2238.4353502642307
diff_x: 0.012763816762759873
-----------
k: 91
loss = 2237.9842784753787
diff_x: 0.019815116861098294
-----------
k: 92
loss = 2237.2442849717495
diff_x: 0.02595180214108256
-----------
k: 93
loss = 2236.3551073486487
diff_x: 0.030593246377733356
-----------
k: 94
loss = 2235.45979500091
diff_x: 0.03356263838494216
-----------
k: 95
loss = 2234.6801842896098
diff_x: 0.03483657715227489
-----------
k: 96
loss = 2234.100019889365
diff_x: 0.034489980614308455
-----------
k: 97
loss = 2233.7572706712813
diff_x: 0.032673181275306676
-----------
k: 98
loss = 2233.6454177679816
diff_x: 0.029596050043128458
-----------
k: 99
loss = 2233.7220302456562
diff_x: 0.025514459427099373
-----------
k: 100
loss = 2233.9219882504854
diff_x: 0.020719872227746492
-----------
k: 101
loss = 2234.1723495115466
diff_x: 0.01553878609905309
-----------
k: 102
loss = 2234.406055728836
diff_x: 0.010373454500112891
-----------
k: 103
loss = 2234.5723219512506
diff_x: 0.005982410256688845
-----------
k: 104
loss = 2234.6424670967663
diff_x: 0.0047322881061895375
-----------
k: 105
loss = 2234.610929702451
diff_x: 0.007396843052769259
-----------
k: 106
loss = 2234.4920889727305
diff_x: 0.010706018079113831
-----------
k: 107
loss = 2234.314142039599
diff_x: 0.013513699133754184
-----------
k: 108
loss = 2234.1116015192406
diff_x: 0.015540255550836928
-----------
k: 109
loss = 2233.9179667151443
diff_x: 0.01670210850462839
-----------
k: 110
loss = 2233.7598387750904
diff_x: 0.01699908530615429
-----------
k: 111
loss = 2233.6532867096203
diff_x: 0.016485117947834575
-----------
k: 112
loss = 2233.6027375873136
diff_x: 0.015254915643287292
-----------
k: 113
loss = 2233.602166570818
diff_x: 0.013434747339125475
-----------
k: 114
loss = 2233.6379844743115
diff_x: 0.011175504132579995
-----------
k: 115
loss = 2233.692811773791
diff_x: 0.008650439658557585
-----------
k: 116
loss = 2233.749299958053
diff_x: 0.006069759509737631
-----------
k: 117
loss = 2233.793290671451
diff_x: 0.003775906059568273
-----------
k: 118
loss = 2233.8158419105775
diff_x: 0.002666702370809423
-----------
k: 119
loss = 2233.8139375729997
diff_x: 0.0035611349105558
-----------
k: 120
loss = 2233.7899713406523
diff_x: 0.005143501310389443
-----------
k: 121
loss = 2233.75030921491
diff_x: 0.006578065376478763
-----------
k: 122
loss = 2233.703356951478
diff_x: 0.007641450527408017
-----------
k: 123
loss = 2233.6575808257085
diff_x: 0.008265874684975845
-----------
k: 124
loss = 2233.619864251923
diff_x: 0.008441775565853156
-----------
k: 125
loss = 2233.594455235099
diff_x: 0.008193815574185455
-----------
k: 126
loss = 2233.5826044578293
diff_x: 0.007571323321302269
-----------
k: 127
loss = 2233.582844965192
diff_x: 0.006642486298587537
-----------
k: 128
loss = 2233.5917493616894
diff_x: 0.005490521369536824
-----------
k: 129
loss = 2233.6049358623495
diff_x: 0.004213580497143451
-----------
k: 130
loss = 2233.6180847951086
diff_x: 0.0029378008022776982
-----------
k: 131
loss = 2233.627765299099
diff_x: 0.0018874931923837659
-----------
k: 132
loss = 2233.6319428596903
diff_x: 0.0015612987062071251
-----------
k: 133
loss = 2233.630122824652
diff_x: 0.002101729169902993
-----------
k: 134
loss = 2233.623164376084
diff_x: 0.002868067210325858
-----------
k: 135
loss = 2233.6128588013958
diff_x: 0.0035323625971921085
-----------
k: 136
loss = 2233.601396813402
diff_x: 0.003996331789367553
-----------
k: 137
loss = 2233.5908506082674
diff_x: 0.0042301433849708334
-----------
k: 138
loss = 2233.5827720187203
diff_x: 0.0042333610437958885
-----------
k: 139
loss = 2233.5779675159624
diff_x: 0.004023665235239136
-----------
k: 140
loss = 2233.576464759367
diff_x: 0.0036318738313427575
-----------
k: 141
loss = 2233.577644073961
diff_x: 0.0030989687148132855
-----------
k: 142
loss = 2233.580479244307
diff_x: 0.002474855713741653
-----------
k: 143
loss = 2233.5838192187116
diff_x: 0.0018215735865187554
-----------
k: 144
loss = 2233.5866456648296
diff_x: 0.0012329860160883229
-----------
k: 145
loss = 2233.5882574588927
diff_x: 0.0009000927677596037
-----------
k: 146
loss = 2233.5883566927178
diff_x: 0.0010180307367700964
-----------
k: 147
loss = 2233.5870355751636
diff_x: 0.0013741007809161918
-----------
k: 148
loss = 2233.584684335867
diff_x: 0.001728486880800606
-----------
k: 149
loss = 2233.5818532703634
diff_x: 0.001995133977801828
-----------
k: 150
loss = 2233.5791059559497
diff_x: 0.0021461255151128634
-----------
k: 151
loss = 2233.5768961231224
diff_x: 0.0021758062324644554
-----------
k: 152
loss = 2233.5754900497873
diff_x: 0.0020907454711238424
-----------
k: 153
loss = 2233.5749429098732
diff_x: 0.001905902515634391
-----------
k: 154
loss = 2233.575124571773
diff_x: 0.0016426088345642405
-----------
k: 155
loss = 2233.5757805720737
diff_x: 0.0013277060542160877
-----------
k: 156
loss = 2233.5766089401272
diff_x: 0.0009950701335057904
-----------
k: 157
loss = 2233.5773335081526
diff_x: 0.0006949226030416716
-----------
k: 158
loss = 2233.5777584764405
diff_x: 0.0005203929404323741
-----------
k: 159
loss = 2233.577795719343
diff_x: 0.000562861335802414
-----------
k: 160
loss = 2233.577463726693
diff_x: 0.0007326753388597918
-----------
k: 161
loss = 2233.576863451346
diff_x: 0.000908945420446059
-----------
k: 162
loss = 2233.5761404620757
diff_x: 0.001042225625871763
-----------
k: 163
loss = 2233.5754441597246
diff_x: 0.001115686078081387
-----------
k: 164
loss = 2233.5748935746296
diff_x: 0.0011256486843925423
-----------
k: 165
loss = 2233.574556138686
diff_x: 0.0010756095118746739
-----------
k: 166
loss = 2233.5744418262484
diff_x: 0.0009739295300446993
-----------
k: 167
loss = 2233.57451121935
diff_x: 0.0008326861103947842
-----------
k: 168
loss = 2233.574693200559
diff_x: 0.0006673422709312315
-----------
k: 169
loss = 2233.574906579219
diff_x: 0.0004981403849813256
-----------
k: 170
loss = 2233.575080078305
diff_x: 0.0003564034070183099
-----------
k: 171
loss = 2233.5751664627674
diff_x: 0.00029379894887346673
-----------
k: 172
loss = 2233.5751486602694
diff_x: 0.00033483661069450856
-----------
k: 173
loss = 2233.5750379212063
diff_x: 0.00042265139153807205
-----------
k: 174
loss = 2233.5748658673106
diff_x: 0.0005061476751029389
-----------
k: 175
loss = 2233.574673344756
diff_x: 0.0005644723197145133
-----------
k: 176
loss = 2233.5744992116
diff_x: 0.000590501793930919
-----------
k: 177
loss = 2233.5743716484853
diff_x: 0.0005833567382896061
-----------
k: 178
loss = 2233.574303540012
diff_x: 0.000545829798290617
-----------
k: 179
loss = 2233.5742922583677
diff_x: 0.0004832955316149139
-----------
k: 180
loss = 2233.574323101591
diff_x: 0.0004032128788430528
-----------
k: 181
loss = 2233.574374922753
diff_x: 0.00031526779875603515
-----------
k: 182
loss = 2233.5744262369694
diff_x: 0.0002330242012706894
-----------
k: 183
loss = 2233.5744602876975
diff_x: 0.00017812579381560123
-----------
k: 184
loss = 2233.5744680697762
diff_x: 0.00017389564382396512
-----------
k: 185
loss = 2233.574448967189
diff_x: 0.00020953771834482626
-----------
k: 186
loss = 2233.5744092880286
diff_x: 0.0002539951785540098
-----------
k: 187
loss = 2233.5743594265164
diff_x: 0.00028967519007878245
-----------
k: 188
loss = 2233.574310577091
diff_x: 0.0003097252878517403
-----------
k: 189
loss = 2233.5742718662336
diff_x: 0.00031221194796638866
-----------
k: 190
loss = 2233.574248512355
diff_x: 0.00029783265790167627
-----------
k: 191
loss = 2233.57424126803
diff_x: 0.00026901143230502965
-----------
k: 192
loss = 2233.574247044952
diff_x: 0.00022948844283186462
-----------
k: 193
loss = 2233.5742603549297
diff_x: 0.00018425497288606575
-----------
k: 194
loss = 2233.574275069111
diff_x: 0.0001401063717186283
-----------
k: 195
loss = 2233.5742860102537
diff_x: 0.0001072402035696108
-----------
k: 196
loss = 2233.574290021001
diff_x: 9.794510237804191e-05
-----------
k: 197
loss = 2233.5742863432547
diff_x: 0.00011172664411936288
-----------
k: 198
loss = 2233.5742763418593
diff_x: 0.00013378215849754827
-----------
k: 199
loss = 2233.574262760407
diff_x: 0.00015306379364348082
-----------
k: 200
loss = 2233.574248777857
diff_x: 0.0001647524462304995
-----------
k: 201
loss = 2233.57423713498
diff_x: 0.00016725096237317667
-----------
k: 202
loss = 2233.5742295335135
diff_x: 0.0001606625282152435
-----------
k: 203
loss = 2233.574226406494
diff_x: 0.00014617091829342315
-----------
k: 204
loss = 2233.574227048105
diff_x: 0.00012576429061185104
-----------
k: 205
loss = 2233.574230003985
diff_x: 0.00010216963721728396
-----------
k: 206
loss = 2233.5742335759624
diff_x: 7.909726839172838e-05
-----------
k: 207
loss = 2233.574236293233
diff_x: 6.188537418957219e-05
-----------
k: 208
loss = 2233.574237237495
diff_x: 5.6532374010566346e-05
-----------
k: 209
loss = 2233.574236166985
diff_x: 6.287832579414703e-05
-----------
k: 210
loss = 2233.5742334452784
diff_x: 7.378853747255994e-05
-----------
k: 211
loss = 2233.5742298291634
diff_x: 8.346646052125769e-05
-----------
k: 212
loss = 2233.5742261957976
diff_x: 8.92104677952152e-05
-----------
k: 213
loss = 2233.574223290155
diff_x: 9.009228957358097e-05
-----------
k: 214
loss = 2233.574221553757
diff_x: 8.615754032572505e-05
-----------
k: 215
loss = 2233.574221063698
diff_x: 7.807729808485085e-05
-----------
k: 216
loss = 2233.574221577316
diff_x: 6.699278248833293e-05
-----------
k: 217
loss = 2233.574222651508
diff_x: 5.448634955354319e-05
-----------
k: 218
loss = 2233.574223792104
diff_x: 4.272030470805368e-05
-----------
k: 219
loss = 2233.574224589077
diff_x: 3.464949509400606e-05
-----------
k: 220
loss = 2233.574224805159
diff_x: 3.293257253321014e-05
-----------
k: 221
loss = 2233.5742244034564
diff_x: 3.663736992574387e-05
-----------
k: 222
loss = 2233.5742235181892
diff_x: 4.210854289267138e-05
-----------
k: 223
loss = 2233.5742223867255
diff_x: 4.6633955188750435e-05
-----------
k: 224
loss = 2233.574221267859
diff_x: 4.8950232602880334e-05
-----------
k: 225
loss = 2233.57422037025
diff_x: 4.86564477965981e-05
-----------
k: 226
loss = 2233.5742198078538
diff_x: 4.585568509842368e-05
-----------
k: 227
loss = 2233.57421958892
diff_x: 4.098899759236453e-05
-----------
k: 228
loss = 2233.574219635063
diff_x: 3.4763317148363675e-05
-----------
k: 229
loss = 2233.574219819591
diff_x: 2.8152778338361947e-05
-----------
k: 230
loss = 2233.5742200111977
diff_x: 2.2477596789963495e-05
-----------
k: 231
loss = 2233.57422011029
diff_x: 1.9331832392100338e-05
-----------
k: 232
loss = 2233.5742200695913
diff_x: 1.9509518610287827e-05
-----------
k: 233
loss = 2233.574219896459
diff_x: 2.1834961535730806e-05
-----------
k: 234
loss = 2233.5742196397523
diff_x: 2.4499396639688786e-05
-----------
k: 235
loss = 2233.574219367761
diff_x: 2.636785895389355e-05
-----------
k: 236
loss = 2233.5742191448962
diff_x: 2.6947129798233605e-05
-----------
k: 237
loss = 2233.5742190137717
diff_x: 2.6132130106538444e-05
-----------
k: 238
loss = 2233.5742189865973
diff_x: 2.4062021883643434e-05
-----------
k: 239
loss = 2233.574219046545
diff_x: 2.1051161927392938e-05
-----------
k: 240
loss = 2233.574219156898
diff_x: 1.756406090320642e-05
-----------
k: 241
loss = 2233.574219274064
diff_x: 1.4229120396978718e-05
-----------
k: 242
loss = 2233.5742193601927
diff_x: 1.1844626303579501e-05
-----------
k: 243
loss = 2233.574219392027
diff_x: 1.1091032358332938e-05
-----------
k: 244
loss = 2233.5742193642664
diff_x: 1.1822691429823184e-05
-----------
k: 245
loss = 2233.5742192875437
diff_x: 1.3155184418079034e-05
-----------
k: 246
loss = 2233.574219182564
diff_x: 1.4307572070113796e-05
-----------
k: 247
loss = 2233.5742190727256
diff_x: 1.4867901628026395e-05
-----------
k: 248
loss = 2233.574218977517
diff_x: 1.4691186503367882e-05
-----------
k: 249
loss = 2233.574218908328
diff_x: 1.3800632922026382e-05
-----------
k: 250
loss = 2233.574218867347
diff_x: 1.2334659732903638e-05
-----------
k: 251
loss = 2233.5742188492127
diff_x: 1.0522495384070985e-05
-----------
k: 252
loss = 2233.574218844404
diff_x: 8.680334534956702e-06
-----------
k: 253
loss = 2233.5742188430504
diff_x: 7.211723563484168e-06
-----------
k: 254
loss = 2233.5742188379913
diff_x: 6.5123487828930815e-06
-----------
k: 255
loss = 2233.5742188263625
diff_x: 6.654492682871248e-06
-----------
k: 256
loss = 2233.574218809532
diff_x: 7.263299937210062e-06
-----------
k: 257
loss = 2233.574218791744
diff_x: 7.888256017341046e-06
-----------
k: 258
loss = 2233.5742187781107
diff_x: 8.250202900591669e-06
-----------
k: 259
loss = 2233.5742187726796
diff_x: 8.231269735825535e-06
-----------
k: 260
loss = 2233.5742187771407
diff_x: 7.82092267489382e-06
-----------
k: 261
loss = 2233.5742187904452
diff_x: 7.081473332768789e-06
-----------
k: 262
loss = 2233.5742188093
diff_x: 6.130400313026414e-06
-----------
k: 263
loss = 2233.5742188292534
diff_x: 5.133908032230146e-06
-----------
k: 264
loss = 2233.5742188459594
diff_x: 4.302827015038795e-06
-----------
k: 265
loss = 2233.574218856236
diff_x: 3.848539355644601e-06
-----------
k: 266
loss = 2233.5742188586573
diff_x: 3.839167902381917e-06
-----------
k: 267
loss = 2233.5742188535987
diff_x: 4.111762022544786e-06
-----------
k: 268
loss = 2233.5742188428153
diff_x: 4.4279585483879485e-06
-----------
k: 269
loss = 2233.574218828763
diff_x: 4.6228502331855125e-06
-----------
k: 270
loss = 2233.574218813889
diff_x: 4.620053675953785e-06
-----------
k: 271
loss = 2233.5742188000922
diff_x: 4.406557811311395e-06
-----------
k: 272
loss = 2233.5742187884643
diff_x: 4.01304920858554e-06
-----------
k: 273
loss = 2233.5742187793085
diff_x: 3.502894054044951e-06
-----------
k: 274
loss = 2233.5742187723718
diff_x: 2.9669299600584383e-06
-----------
k: 275
loss = 2233.574218767164
diff_x: 2.5183051986069627e-06
-----------
k: 276
loss = 2233.5742187632477
diff_x: 2.2660688966147346e-06
-----------
k: 277
loss = 2233.57421876041
diff_x: 2.2441655469259173e-06
-----------
k: 278
loss = 2233.574218758693
diff_x: 2.3713048234654237e-06
-----------
k: 279
loss = 2233.574218758301
diff_x: 2.524627570164197e-06
-----------
k: 280
loss = 2233.5742187594415
diff_x: 2.6153583636595175e-06
-----------
k: 281
loss = 2233.5742187621727
diff_x: 2.601059078146789e-06
-----------
k: 282
loss = 2233.574218766305
diff_x: 2.4744393643314445e-06
-----------
k: 283
loss = 2233.5742187713927
diff_x: 2.2531018674740176e-06
-----------
k: 284
loss = 2233.574218776804
diff_x: 1.973315637246996e-06
-----------
k: 285
loss = 2233.5742187818464
diff_x: 1.6864320447059732e-06
-----------
k: 286
loss = 2233.574218785904
diff_x: 1.4538827032882195e-06
-----------
k: 287
loss = 2233.574218788549
diff_x: 1.3291744926308756e-06
-----------
k: 288
loss = 2233.574218789597
diff_x: 1.3216201733903517e-06
-----------
k: 289
loss = 2233.5742187891087
diff_x: 1.3846841101524175e-06
-----------
k: 290
loss = 2233.5742187873348
diff_x: 1.4555357303879187e-06
-----------
k: 291
loss = 2233.5742187846413
diff_x: 1.4897288797344093e-06
-----------
k: 292
loss = 2233.574218781424
diff_x: 1.4666990336416055e-06
-----------
k: 293
loss = 2233.5742187780447
diff_x: 1.3845308065572892e-06
-----------
k: 294
loss = 2233.5742187747937
diff_x: 1.2548711844064963e-06
-----------
k: 295
loss = 2233.5742187718774
diff_x: 1.099594942121576e-06
-----------
k: 296
loss = 2233.5742187694295
diff_x: 9.483406957286489e-07
-----------

Termino!
lambda vale: 10
lr vale: 0.1
x_true vale:
tensor([0.2972, 0.2972, 0.2972, 0.2972, 0.2972, 0.2972, 0.2972, 0.2972, 0.2972,
        0.2972, 0.2972], dtype=torch.float64)
x optimo vale:
tensor([0.5555, 0.4640, 0.3379, 0.3015, 0.3438, 0.2049, 0.5302, 0.9004, 0.7779,
        0.6242, 0.4645], dtype=torch.float64)
la diferencia entre y e y_pred = T(x_optimo) vale:
tensor([ 1.1449e-05-1.0786e-05j, -2.6068e-04+1.8525e-04j,
        -1.2926e-03+9.6212e-04j, -1.2113e-03+1.0671e-03j,
         1.0892e-02-8.0175e-03j, -1.1477e-02+8.3840e-03j,
         2.7640e-03-2.0646e-03j, -3.0615e-02+2.3235e-02j,
         5.5863e-02-3.7159e-02j,  7.7260e-01-5.7068e-01j,
        -1.1989e+00+8.8374e-01j,  2.7838e+00-1.9841e+00j,
        -1.1318e+00+7.3575e-01j, -2.4730e-01+1.9082e-01j,
         1.3689e+00-9.2478e-01j], grad_fn=<SliceBackward0>)
y vale:
tensor([ 0.6927-0.4494j, -1.2144+0.8468j,  0.7346-0.4811j, -1.2207+0.8452j,
        -0.0748+0.0995j,  0.1770-0.0949j, -1.2252+0.8545j,  0.6922-0.4492j,
        -1.2258+0.8550j,  0.6927-0.4494j, -1.2144+0.8468j],
       grad_fn=<SliceBackward0>)
y_pred vale:
tensor([-1.2074+0.8354j, -0.0828+0.1050j,  0.1664-0.0871j, -1.2146+0.8467j,
         0.6816-0.4414j, -1.2151+0.8472j,  0.6820-0.4416j, -1.2038+0.8390j,
         0.7245-0.4736j, -1.2074+0.8354j, -0.0828+0.1050j],
       grad_fn=<SliceBackward0>)
