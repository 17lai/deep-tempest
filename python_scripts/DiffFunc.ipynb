{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be tensor with float (each bit)\n",
    "def IndA_diff(input):\n",
    "    weights = torch.tensor([[-7.8433e-04, 37.006, 37.006, 37.006, 37.005, 37.006, 37.006, 37.007]],dtype=torch.float64)\n",
    "    bias = torch.tensor([-131.3873],dtype=torch.float64)\n",
    "    linear_output = torch.matmul(input, weights.t()) + bias\n",
    "    output = torch.sigmoid(linear_output)\n",
    "\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de regresión logística1\n",
    "class LogisticRegressionB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionB, self).__init__()\n",
    "        self.linear1 = nn.Linear(9, 20,dtype=torch.float64) \n",
    "        self.linear2 = nn.Linear(20, 10,dtype=torch.float64)\n",
    "        self.linear3 = nn.Linear(10, 1,dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de regresión logística\n",
    "class LogisticRegressionD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionD, self).__init__()\n",
    "        self.linear1 = nn.Linear(9, 10,dtype=torch.float64) # 9 entradas y 20 salida\n",
    "        self.linear2 = nn.Linear(10, 5,dtype=torch.float64)\n",
    "        self.linear3 = nn.Linear(5, 1,dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndB = LogisticRegressionB()\n",
    "state_dictB = torch.load('indicatrizB.pth')\n",
    "IndB.load_state_dict(state_dictB)\n",
    "#input must be tensor with float (each bit)\n",
    "def IndB_diff(bits):\n",
    "    return IndB(bits).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 60,dtype=torch.float64)  \n",
    "        self.fc2 = nn.Linear(60, 30,dtype=torch.float64)\n",
    "        self.fc3 = nn.Linear(30, 20,dtype=torch.float64)\n",
    "        self.fc4 = nn.Linear(20, 1,dtype=torch.float64)    \n",
    "        self.sigmoid = nn.Sigmoid()  # Función de activación sigmoide\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndE = Net()\n",
    "state_dictE = torch.load('indicatrizE.pth')\n",
    "IndE.load_state_dict(state_dictE)\n",
    "#bits must be tensor and cnt integer\n",
    "def IndE_diff(bits,cnt):\n",
    "    cnt = torch.tensor([cnt],dtype=torch.float64)\n",
    "    input = torch.cat((bits,cnt))\n",
    "    return IndE(input).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndC = Net()\n",
    "state_dictC = torch.load('indicatrizC.pth')\n",
    "IndC.load_state_dict(state_dictC)\n",
    "#bits must be tensor and cnt integer\n",
    "def IndC_diff(bits,cnt):\n",
    "    cnt = torch.tensor([cnt],dtype=torch.float64)\n",
    "    input = torch.cat((bits,cnt))\n",
    "    return IndC(input).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndD = LogisticRegressionD()\n",
    "state_dictD = torch.load('indicatrizD.pth')\n",
    "IndD.load_state_dict(state_dictD)\n",
    "#input must be tensor with float (each bit)\n",
    "def IndD_diff(bits):\n",
    "    return IndD(bits).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NegBit_diff(x):\n",
    "    return 1 / (1 + np.exp(-(-15.43*x + 7.51)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Real2Bit_diff(x):\n",
    "    return 1 / (1 + np.exp(-(-5.43 + 10.81*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XNOR_diff(x1, x2):\n",
    "    fc1_weight = torch.tensor([[4.7662,  4.8464],[-0.1215,  1.3168],[ 2.6322,  2.3068],[-0.0951, -0.4683]],dtype=torch.float64)\n",
    "    fc1_bias = torch.tensor([-1.5654,  0.3904, -3.6841, -0.0062],dtype=torch.float64)\n",
    "    fc2_weight = torch.tensor([[-5.6381,  1.5594,  5.0998, -0.2311]],dtype=torch.float64)\n",
    "    fc2_bias = torch.tensor([1.7433],dtype=torch.float64)\n",
    "\n",
    "    x = torch.tensor([x1, x2],dtype=torch.float64)\n",
    "    fc1_output = torch.sigmoid(torch.matmul(x, fc1_weight.transpose(0, 1)) + fc1_bias)\n",
    "    fc2_output = torch.sigmoid(torch.matmul(fc1_output, fc2_weight.transpose(0, 1)) + fc2_bias)\n",
    "\n",
    "    return fc2_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_diff(x1, x2):\n",
    "    fc1_weight = torch.tensor([[-3.8973,  4.0330],[-4.1031,  3.8928],[-0.6775,  0.8108],[ 2.3834, -2.4550]],dtype=torch.float64)\n",
    "    fc1_bias = torch.tensor([ 2.2917, -2.1209, -0.6751, -1.6954],dtype=torch.float64)\n",
    "    fc2_weight = torch.tensor([[-4.5110,  5.7411,  1.0059,  2.4664]],dtype=torch.float64)\n",
    "    fc2_bias = torch.tensor([0.8839],dtype=torch.float64)\n",
    "\n",
    "    x = torch.tensor([x1, x2],dtype=torch.float64)\n",
    "    fc1_output = torch.sigmoid(torch.matmul(x, fc1_weight.transpose(0, 1)) + fc1_bias)\n",
    "    fc2_output = torch.sigmoid(torch.matmul(fc1_output, fc2_weight.transpose(0, 1)) + fc2_bias)\n",
    "\n",
    "    return fc2_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_diff(x1, x2):\n",
    "    weight = torch.tensor([[13.5223, 13.5223]],dtype=torch.float64)\n",
    "    bias = torch.tensor([-6.3024],dtype=torch.float64)\n",
    "    x = torch.tensor([x1, x2],dtype=torch.float64)\n",
    "    output = torch.sigmoid(torch.matmul(x, weight.transpose(0, 1)) + bias)\n",
    "\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be float (each bit)\n",
    "def q_m_diff(input):\n",
    "    input_cp = input.copy()\n",
    "    t_input = torch.tensor(input_cp,dtype=torch.float64)\n",
    "    output = torch.tensor([t_input[0], 0, 0, 0, 0, 0, 0, 0, 0],dtype=torch.float64)\n",
    "    for bit in range(1, 8):\n",
    "        output[bit] = IndA_diff(t_input) * Real2Bit_diff(XNOR_diff(output[bit-1], t_input[bit])) + (1 - IndA_diff(t_input)) * Real2Bit_diff(XOR_diff(output[bit-1],t_input[bit]))\n",
    "    output[8] = 1 - IndA_diff(t_input)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be float (each bit) example: [0.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0], 2.0\n",
    "#output are tensors\n",
    "def TMDS_diff(pixel_bits,cnt):\n",
    "    bits_inversos = pixel_bits[::-1]\n",
    "    q_m = q_m_diff(bits_inversos)\n",
    "    q_m = Real2Bit_diff(q_m)\n",
    "    output = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0],dtype=torch.float64)\n",
    "    for bit in range(0,8):\n",
    "        output[bit] = q_m[bit] * OR_diff(IndE_diff(q_m[:8],cnt) * IndB_diff(q_m[:9]),(1-IndC_diff(q_m[:8],cnt)) * (1-IndE_diff(q_m[:8],cnt))) + NegBit_diff(q_m[bit]) * OR_diff((1 - IndB_diff(q_m[:9])) * IndE_diff(q_m[:8],cnt),IndC_diff(q_m[:8],cnt) * (1 - IndE_diff(q_m[:8],cnt)))\n",
    "    output[8] = q_m[8]\n",
    "    output[9] = IndE_diff(q_m[:8],cnt) * NegBit_diff(q_m[8]) + (1 - IndE_diff(q_m[:8],cnt)) * IndC_diff(q_m[:8],cnt)\n",
    "    new_cnt = IndE_diff(q_m[:8],cnt) * ((cnt + torch.sum(q_m[:8] < 0.5).item() - torch.sum(q_m[:8] > 0.5).item()) * IndD_diff(q_m) + (cnt + torch.sum(q_m[:8] > 0.5).item() - torch.sum(q_m[:8] < 0.5).item()) * (1 - IndD_diff(q_m))) + (1 - IndE_diff(q_m[:8],cnt)) * ((cnt + 2 * q_m[8] + torch.sum(q_m[:8] < 0.5).item() - torch.sum(q_m[:8] > 0.5).item()) * IndC_diff(q_m[:8],cnt) + (cnt - 2 * NegBit_diff(q_m[8]) + torch.sum(q_m[:8] > 0.5).item() - torch.sum(q_m[:8] < 0.5).item()) * (1 - IndC_diff(q_m[:8],cnt)))\n",
    "    return output,new_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pixel2Bit_diff(pixel):\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for i in range(1,9):\n",
    "        output[i-1] = 1 / (1 + np.exp(-(6*(pixel-2**(8-i)+0.5))))  #0.5 to adjust for the sigmoid so at 127.5 is at 0.5 and at 128 is already at 1\n",
    "        if pixel >= 2**(8-i):\n",
    "            pixel = pixel - 2**(8-i)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2950684999667505e-244,\n",
       " 1.3485799642996046e-77,\n",
       " 0.999999694097773,\n",
       " 6.639677199580733e-36,\n",
       " 4.658886145103376e-15,\n",
       " 0.00012339457598623172,\n",
       " 0.9525741268224334,\n",
       " 0.04742587317756678]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixell = 34\n",
    "Pixel2Bit_diff(pixell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que toma como entrada el armonico a sintonizar y las dimensiones de la imagen a espiar y devuelve un array con taps de g(t)\n",
    "def g_taps(dim_vertical, dim_horizontal, armonico):\n",
    "\n",
    "    #defino variables iniciales\n",
    "    f_b = 10 * (dim_vertical * dim_horizontal * 60)\n",
    "    f_sdr = 50e6\n",
    "    harm = armonico * f_b\n",
    "    \n",
    "    #para el correcto funcionamiento: dependiendo del armonico, elijo cuantas muestras por pulso\n",
    "    if (armonico < 5 ):\n",
    "        muestras_por_pulso  = 10\n",
    "    else:\n",
    "        muestras_por_pulso  = 20\n",
    "\n",
    "    samp_rate = muestras_por_pulso * f_b\n",
    "    H_samples = dim_horizontal * muestras_por_pulso\n",
    "\n",
    "    #creo el pulso\n",
    "    t_continuous = np.linspace(start = 0, stop = H_samples/samp_rate, num = H_samples, endpoint= False)\n",
    "    pulso = np.zeros(H_samples)\n",
    "    pulso[:muestras_por_pulso] = 0.7/255\n",
    "\n",
    "    #traslado el espectro del pulso el armonico correspondiente\n",
    "    frec_armonico = np.exp(-2j*np.pi*harm*t_continuous)\n",
    "    pulso_complejo = pulso*frec_armonico\n",
    "\n",
    "    #creo el lpf del sdr\n",
    "    b, a = signal.butter(6, f_sdr/2, fs=samp_rate, btype='lowpass', analog=False)\n",
    "\n",
    "    #filtro con lpf el pulso multiplicado por armonico. El resultado es g\n",
    "    g_t = signal.lfilter(b, a, pulso_complejo)\n",
    "\n",
    "    # si arminico crece, necesito mas taps\n",
    "    if (armonico < 5):\n",
    "        g_t = g_t[:1500]\n",
    "    else:\n",
    "        g_t = g_t[:3000]\n",
    "\n",
    "    return g_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def g_simplified(input):\n",
    "#   \n",
    "#    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(img, armonico):\n",
    "    filas, columnas = img.shape\n",
    "    img_salida = img.copy()\n",
    "    bits_codificados = np.zeros((columnas,10))\n",
    "    g_t = g_taps(filas, columnas, armonico)\n",
    "    size_g_t = g_t.shape\n",
    "    for i in range(filas):\n",
    "        cnt = 0\n",
    "        for j in range(columnas):\n",
    "            pixel = img[i,j]\n",
    "            pixel_bits = Pixel2Bit_diff(pixel)\n",
    "            bits_cods, cnt = TMDS_diff(pixel_bits, cnt)\n",
    "            bits_codificados[j,:] = bits_cods\n",
    "        cadena_bits = bits_codificados.flatten()\n",
    "        #calculo y[n] en la linea horizontal i\n",
    "        for n in range(columnas):\n",
    "            g_t_shift = g_t.copy()\n",
    "            largo_g = g_t.shape\n",
    "            for k in range(0, 10*n):\n",
    "                g_t_shift[k] = g_t[10*n - k]\n",
    "            for t in range(10*n, )\n",
    "            \n",
    "\n",
    "\n",
    "            acum = 0\n",
    "            for p in range(10*n, size_g_t):\n",
    "                acum = acum + cadena_bits[p] * g_t[p -10*n]\n",
    "            img_salida[i, n] = acum\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
