{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from scipy import signal\n",
    "import time #testing de tiempos\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torchaudio\n",
    "from torchaudio import functional as F\n",
    "import cProfile #testing de tiempos\n",
    "from joblib import Parallel, delayed  #multithreading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be tensor with float (each bit)\n",
    "def IndA_diff(input):\n",
    "    weights = torch.tensor([[-7.8433e-04, 37.006, 37.006, 37.006, 37.005, 37.006, 37.006, 37.007]],dtype=torch.float64)\n",
    "    bias = torch.tensor([-131.3873],dtype=torch.float64)\n",
    "    linear_output = torch.matmul(input, weights.t()) + bias\n",
    "    output = torch.sigmoid(linear_output)\n",
    "\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de regresión logística1\n",
    "class LogisticRegressionB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionB, self).__init__()\n",
    "        self.linear1 = nn.Linear(9, 20,dtype=torch.float64) \n",
    "        self.linear2 = nn.Linear(20, 10,dtype=torch.float64)\n",
    "        self.linear3 = nn.Linear(10, 1,dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de regresión logística\n",
    "class LogisticRegressionD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionD, self).__init__()\n",
    "        self.linear1 = nn.Linear(9, 10,dtype=torch.float64) # 9 entradas y 20 salida\n",
    "        self.linear2 = nn.Linear(10, 5,dtype=torch.float64)\n",
    "        self.linear3 = nn.Linear(5, 1,dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndB = LogisticRegressionB()\n",
    "state_dictB = torch.load('indicatrizB.pth')\n",
    "IndB.load_state_dict(state_dictB)\n",
    "#input must be tensor with float (each bit)\n",
    "def IndB_diff(bits):\n",
    "    return IndB(bits).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 15,dtype=torch.float64)  \n",
    "        self.fc2 = nn.Linear(15, 1,dtype=torch.float64)  \n",
    "        self.sigmoid = nn.Sigmoid()  # Función de activación sigmoide\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndE = Net()\n",
    "state_dictE = torch.load('indicatrizE.pth', map_location=torch.device('cpu'))\n",
    "IndE.load_state_dict(state_dictE)\n",
    "#bits must be tensor and cnt integer\n",
    "def IndE_diff(bits,cnt):\n",
    "    cnt = torch.tensor([cnt],dtype=torch.float64)\n",
    "    input = torch.cat((bits,cnt))\n",
    "    return IndE(input).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndC = Net()\n",
    "state_dictC = torch.load('indicatrizC.pth', map_location=torch.device('cpu'))\n",
    "IndC.load_state_dict(state_dictC)\n",
    "#bits must be tensor and cnt integer\n",
    "def IndC_diff(bits,cnt):\n",
    "    cnt = torch.tensor([cnt],dtype=torch.float64)\n",
    "    input = torch.cat((bits,cnt))\n",
    "    return IndC(input).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndD = LogisticRegressionD()\n",
    "state_dictD = torch.load('indicatrizD.pth')\n",
    "IndD.load_state_dict(state_dictD)\n",
    "#input must be tensor with float (each bit)\n",
    "def IndD_diff(bits):\n",
    "    return IndD(bits).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NegBit_diff(x):\n",
    "    return 1 / (1 + np.exp(-(-15.43*x + 7.51)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Real2Bit_diff(x):\n",
    "    return 1 / (1 + np.exp(-(-5.43 + 10.81*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XNOR_diff(x1, x2):\n",
    "    fc1_weight = torch.tensor([[4.7662,  4.8464],[-0.1215,  1.3168],[ 2.6322,  2.3068],[-0.0951, -0.4683]],dtype=torch.float64)\n",
    "    fc1_bias = torch.tensor([-1.5654,  0.3904, -3.6841, -0.0062],dtype=torch.float64)\n",
    "    fc2_weight = torch.tensor([[-5.6381,  1.5594,  5.0998, -0.2311]],dtype=torch.float64)\n",
    "    fc2_bias = torch.tensor([1.7433],dtype=torch.float64)\n",
    "\n",
    "    x = torch.tensor([x1, x2],dtype=torch.float64)\n",
    "    fc1_output = torch.sigmoid(torch.matmul(x, fc1_weight.transpose(0, 1)) + fc1_bias)\n",
    "    fc2_output = torch.sigmoid(torch.matmul(fc1_output, fc2_weight.transpose(0, 1)) + fc2_bias)\n",
    "\n",
    "    return fc2_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_diff(x1, x2):\n",
    "    fc1_weight = torch.tensor([[-3.8973,  4.0330],[-4.1031,  3.8928],[-0.6775,  0.8108],[ 2.3834, -2.4550]],dtype=torch.float64)\n",
    "    fc1_bias = torch.tensor([ 2.2917, -2.1209, -0.6751, -1.6954],dtype=torch.float64)\n",
    "    fc2_weight = torch.tensor([[-4.5110,  5.7411,  1.0059,  2.4664]],dtype=torch.float64)\n",
    "    fc2_bias = torch.tensor([0.8839],dtype=torch.float64)\n",
    "\n",
    "    x = torch.tensor([x1, x2],dtype=torch.float64)\n",
    "    fc1_output = torch.sigmoid(torch.matmul(x, fc1_weight.transpose(0, 1)) + fc1_bias)\n",
    "    fc2_output = torch.sigmoid(torch.matmul(fc1_output, fc2_weight.transpose(0, 1)) + fc2_bias)\n",
    "\n",
    "    return fc2_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_diff(x1, x2):\n",
    "    weight = torch.tensor([[13.5223, 13.5223]],dtype=torch.float64)\n",
    "    bias = torch.tensor([-6.3024],dtype=torch.float64)\n",
    "    x = torch.tensor([x1, x2],dtype=torch.float64)\n",
    "    output = torch.sigmoid(torch.matmul(x, weight.transpose(0, 1)) + bias)\n",
    "\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be float (each bit)\n",
    "def q_m_diff(input):\n",
    "    t_input = torch.tensor(input.copy(),dtype=torch.float64)\n",
    "    output = torch.tensor([t_input[0], 0, 0, 0, 0, 0, 0, 0, 0],dtype=torch.float64)\n",
    "    IndA = IndA_diff(t_input)\n",
    "    for bit in range(1, 8):\n",
    "        output[bit] = IndA * Real2Bit_diff(XNOR_diff(output[bit-1], t_input[bit])) + (1 - IndA) * Real2Bit_diff(XOR_diff(output[bit-1],t_input[bit]))\n",
    "    output[8] = 1 - IndA\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be float (each bit) example: [0.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0], 2.0\n",
    "#output are tensors\n",
    "def TMDS_diff(pixel_bits,cnt):\n",
    "    bits_inversos = pixel_bits[::-1]\n",
    "    q_m = q_m_diff(bits_inversos)\n",
    "    q_m = Real2Bit_diff(q_m)\n",
    "    output = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0],dtype=torch.float64)\n",
    "    IndB = IndB_diff(q_m[:9])\n",
    "    IndE = IndE_diff(q_m[:8],cnt)\n",
    "    IndC = IndC_diff(q_m[:8],cnt)\n",
    "    Neg_q = NegBit_diff(q_m[:9])\n",
    "    IndD = IndD_diff(q_m)\n",
    "    output[:8] = q_m[:8] * OR_diff( IndE * IndB, (1-IndC) * (1-IndE)) + Neg_q[:8] * OR_diff((1 - IndB) * IndE, IndC * (1 - IndE))\n",
    "    output[8] = q_m[8]\n",
    "    output[9] = IndE * Neg_q[8] + (1 - IndE) * IndC\n",
    "    new_cnt = IndE * ((cnt + torch.sum(q_m[:8] < 0.5).item() - torch.sum(q_m[:8] > 0.5).item()) * IndD + (cnt + torch.sum(q_m[:8] > 0.5).item() - torch.sum(q_m[:8] < 0.5).item()) * (1 - IndD)) + (1 - IndE) * ((cnt + 2 * q_m[8] + torch.sum(q_m[:8] < 0.5).item() - torch.sum(q_m[:8] > 0.5).item()) * IndC + (cnt - 2 * Neg_q[8] + torch.sum(q_m[:8] > 0.5).item() - torch.sum(q_m[:8] < 0.5).item()) * (1 - IndC))\n",
    "    return output,new_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if x >= 0:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    else:\n",
    "        return np.exp(x) / (1 + np.exp(x))\n",
    "\n",
    "def Pixel2Bit_diff(pixel):\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for i in range(1,9):\n",
    "        output[i-1] = sigmoid(10*(pixel-2**(8-i)+0.5))  # 0.5 para ajustar la sigmoidal\n",
    "        if pixel >= 2**(8-i):\n",
    "            pixel = pixel - 2**(8-i)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que toma como entrada el armonico a sintonizar y las dimensiones de la imagen a espiar y devuelve un array con taps de g(t)\n",
    "def g_taps(dim_vertical, dim_horizontal, armonico):\n",
    "\n",
    "    #defino variables iniciales\n",
    "    f_b = 10 * (dim_vertical * dim_horizontal * 60)\n",
    "    f_sdr = 50e6\n",
    "    harm = armonico * f_b\n",
    "    \n",
    "    #para el correcto funcionamiento: dependiendo del armonico, elijo cuantas muestras por pulso\n",
    "    if (armonico < 5 ):\n",
    "        muestras_por_pulso  = 10\n",
    "    else:\n",
    "        muestras_por_pulso  = 20\n",
    "\n",
    "    samp_rate = muestras_por_pulso * f_b\n",
    "    H_samples = dim_horizontal * muestras_por_pulso\n",
    "\n",
    "    #creo el pulso\n",
    "    t_continuous = np.linspace(start = 0, stop = H_samples/samp_rate, num = H_samples, endpoint= False)\n",
    "    pulso = np.zeros(H_samples)\n",
    "    pulso[:muestras_por_pulso] = 0.7/255\n",
    "\n",
    "    #traslado el espectro del pulso el armonico correspondiente\n",
    "    frec_armonico = np.exp(-2j*np.pi*harm*t_continuous)\n",
    "    pulso_complejo = pulso*frec_armonico\n",
    "\n",
    "    #creo el lpf del sdr\n",
    "    b, a = signal.butter(6, f_sdr/2, fs=samp_rate, btype='lowpass', analog=False)\n",
    "\n",
    "    #filtro con lpf el pulso multiplicado por armonico. El resultado es g\n",
    "    g_t = signal.lfilter(b, a, pulso_complejo)\n",
    "\n",
    "    # si arminico crece, necesito mas taps\n",
    "    if (armonico < 5):\n",
    "        g_t = g_t[:1500]\n",
    "    else:\n",
    "        g_t = g_t[:3000]\n",
    "\n",
    "    g_t_max = np.max(np.abs(g_t))\n",
    "    g_t = g_t / g_t_max\n",
    "\n",
    "    return torch.tensor(g_t,dtype = torch.complex64).reshape(1,1,len(g_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMDS_2_row(multiplicador,cant_filas,img,columnas, g_t, padding):\n",
    "    #bits_cod_filas =  torch.zeros(10*columnas*cant_filas,dtype = torch.complex64)\n",
    "    img_salida = torch.zeros((cant_filas, columnas + 300))\n",
    "    for i in range(multiplicador*cant_filas, cant_filas*(multiplicador+1)):\n",
    "        cnt = 0\n",
    "        bits_cod_filas =  torch.zeros((1, 1, 10*columnas),dtype = torch.complex64)\n",
    "        bits_cod_filas = torch.cat((torch.zeros((1,1,1500), dtype = torch.complex64), bits_cod_filas), dim = 2)\n",
    "        for j in range(columnas):\n",
    "            pixel = img[i,j]\n",
    "            pixel_bits = Pixel2Bit_diff(pixel)\n",
    "            pixel_cod,cnt = TMDS_diff(pixel_bits, cnt)  \n",
    "            bits_cod_filas[0,0,1500 + j*10:1500 + (j+1)*10] = pixel_cod\n",
    "        bits_cod_filas = torch.cat((bits_cod_filas, torch.zeros((1,1,1500), dtype = torch.complex64)),  dim = 2)\n",
    "        img_salida[i,:] = nn.functional.conv1d(bits_cod_filas, g_t, stride = 10, padding = padding, bias = None)[0,0,:]\n",
    "    return img_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mayor_divisor(a, b): \n",
    "    while b != 0:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "def Calc_filas_por_thread(filas, threads):  #calculo la max cantidad de filas para que todos calculen la misma cantidad y no sobrem filas, para pasarle a cada hilo de forma de optimizar el uso de los hilos. Pasarle de a pocas filas es ineficiente\n",
    "    divisor = encontrar_mayor_divisor(filas,threads)\n",
    "    return filas // divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le saque la conv para hacer pruebas \n",
    "def forward(img, armonico,num_threads):\n",
    "    filas, columnas = img.shape\n",
    "    #imagen_salida = np.zeros((filas, columnas + 300))\n",
    "    #bits_codificados = torch.zeros(10*columnas*filas,dtype = torch.complex64)\n",
    "    g_t = g_taps(filas, columnas, armonico)\n",
    "    size_g_t = g_t.numel()    \n",
    "    padding = (size_g_t - 8)//2\n",
    "    filas_por_thread = Calc_filas_por_thread(filas,num_threads)\n",
    "    result = Parallel(n_jobs=num_threads)(delayed(TMDS_2_row)(multiplicador,filas_por_thread,img,columnas, g_t, padding) for multiplicador in range(num_threads)) # da mejores resultados por poquito el multiprocessing (Pool)\n",
    "    if num_threads == 1:\n",
    "        imagen_salida = result[0]\n",
    "    else:\n",
    "        imagen_salida = result[0]\n",
    "        for i in range(1, len(result)):\n",
    "            imagen_salida = torch.cat(imagen_salida, result[i], dim = 1)\n",
    "\n",
    "    return imagen_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m num_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# elegir numeros de hilos del cpu (dejar alguno libre para que no explote la PC)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#cProfile.runctx('forward(imag,armonico)', globals(), locals()) \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m imagen \u001b[39m=\u001b[39m forward(img, armonico,num_threads)\n",
      "Cell \u001b[0;32mIn[75], line 10\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(img, armonico, num_threads)\u001b[0m\n\u001b[1;32m      8\u001b[0m padding \u001b[39m=\u001b[39m (size_g_t \u001b[39m-\u001b[39m \u001b[39m8\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m      9\u001b[0m filas_por_thread \u001b[39m=\u001b[39m Calc_filas_por_thread(filas,num_threads)\n\u001b[0;32m---> 10\u001b[0m result \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mnum_threads)(delayed(TMDS_2_row)(multiplicador,filas_por_thread,img,columnas, g_t, padding) \u001b[39mfor\u001b[39;49;00m multiplicador \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_threads)) \u001b[39m# da mejores resultados por poquito el multiprocessing (Pool)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m num_threads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     12\u001b[0m     imagen_salida \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "Cell \u001b[0;32mIn[73], line 11\u001b[0m, in \u001b[0;36mTMDS_2_row\u001b[0;34m(multiplicador, cant_filas, img, columnas, g_t, padding)\u001b[0m\n\u001b[1;32m      9\u001b[0m     pixel \u001b[39m=\u001b[39m img[i,j]\n\u001b[1;32m     10\u001b[0m     pixel_bits \u001b[39m=\u001b[39m Pixel2Bit_diff(pixel)\n\u001b[0;32m---> 11\u001b[0m     pixel_cod,cnt \u001b[39m=\u001b[39m TMDS_diff(pixel_bits, cnt)  \n\u001b[1;32m     12\u001b[0m     bits_cod_filas[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1500\u001b[39m \u001b[39m+\u001b[39m j\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m:\u001b[39m1500\u001b[39m \u001b[39m+\u001b[39m (j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m] \u001b[39m=\u001b[39m pixel_cod\n\u001b[1;32m     13\u001b[0m bits_cod_filas \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((bits_cod_filas, torch\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1500\u001b[39m), dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcomplex64)),  dim \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mTMDS_diff\u001b[0;34m(pixel_bits, cnt)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTMDS_diff\u001b[39m(pixel_bits,cnt):\n\u001b[1;32m      4\u001b[0m     bits_inversos \u001b[39m=\u001b[39m pixel_bits[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     q_m \u001b[39m=\u001b[39m q_m_diff(bits_inversos)\n\u001b[1;32m      6\u001b[0m     q_m \u001b[39m=\u001b[39m Real2Bit_diff(q_m)\n\u001b[1;32m      7\u001b[0m     output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m],dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64)\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mq_m_diff\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      5\u001b[0m IndA \u001b[39m=\u001b[39m IndA_diff(t_input)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m bit \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     output[bit] \u001b[39m=\u001b[39m IndA \u001b[39m*\u001b[39m Real2Bit_diff(XNOR_diff(output[bit\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], t_input[bit])) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m IndA) \u001b[39m*\u001b[39m Real2Bit_diff(XOR_diff(output[bit\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],t_input[bit]))\n\u001b[1;32m      8\u001b[0m output[\u001b[39m8\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m IndA\n\u001b[1;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_path = '../images/VAMO!!.png'\n",
    "img = np.asarray(Image.open(image_path))[:,:,0]\n",
    "#img = np.zeros((256,256))\n",
    "armonico = 3\n",
    "num_threads = 1  # elegir numeros de hilos del cpu (dejar alguno libre para que no explote la PC)\n",
    "#cProfile.runctx('forward(imag,armonico)', globals(), locals()) \n",
    "imagen = forward(img, armonico,num_threads)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
