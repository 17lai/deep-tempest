{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be tensor with float (each bit)\n",
    "def IndA_diff(input):\n",
    "    weights = torch.tensor([[-7.8433e-04, 37.006, 37.006, 37.006, 37.005, 37.006, 37.006, 37.007]])\n",
    "    bias = torch.tensor([-131.3873])\n",
    "    linear_output = torch.matmul(input, weights.t()) + bias\n",
    "    output = torch.sigmoid(linear_output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be tensor with float (each bit)\n",
    "def IndB_diff(input):\n",
    "    weights = torch.tensor([[-0.4066, -0.4066, -0.4066, -0.4066, -0.4066, -0.4066, -0.4066, 20.1961]])\n",
    "    bias = torch.tensor([-8.4722])\n",
    "    linear_output = torch.matmul(input, weights.t()) + bias\n",
    "    output = torch.sigmoid(linear_output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndC_diff(bits,cnt):\n",
    "   \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be tensor with float (each bit)\n",
    "def IndD_diff(input):\n",
    "    weights = torch.tensor([[ 0.3999,0.3999,0.3999, 0.3999, 0.3999, 0.3999, 0.3999,-15.5119]])\n",
    "    bias = torch.tensor([6.1550])\n",
    "    linear_output = torch.matmul(input, weights.t()) + bias\n",
    "    output = torch.sigmoid(linear_output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndE_diff(bits,cnt):\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NegBit_diff(x):\n",
    "    return 1 / (1 + np.exp(-15.43*x + 7.51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49375032550048975"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Real2Bit_diff(x):\n",
    "    return 1 / (1 + np.exp(-(-5.43 + 10.81*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XNOR_diff(x1, x2):\n",
    "    fc1_weight = torch.tensor([[4.7662,  4.8464],[-0.1215,  1.3168],[ 2.6322,  2.3068],[-0.0951, -0.4683]])\n",
    "    fc1_bias = torch.tensor([-1.5654,  0.3904, -3.6841, -0.0062])\n",
    "    fc2_weight = torch.tensor([[-5.6381,  1.5594,  5.0998, -0.2311]])\n",
    "    fc2_bias = torch.tensor([1.7433])\n",
    "\n",
    "    x = torch.tensor([x1, x2]).float()\n",
    "    fc1_output = torch.sigmoid(torch.matmul(x, fc1_weight.transpose(0, 1)) + fc1_bias)\n",
    "    fc2_output = torch.sigmoid(torch.matmul(fc1_output, fc2_weight.transpose(0, 1)) + fc2_bias)\n",
    "\n",
    "    return fc2_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_diff(x1, x2):\n",
    "    fc1_weight = torch.tensor([[-3.8973,  4.0330],[-4.1031,  3.8928],[-0.6775,  0.8108],[ 2.3834, -2.4550]])\n",
    "    fc1_bias = torch.tensor([ 2.2917, -2.1209, -0.6751, -1.6954])\n",
    "    fc2_weight = torch.tensor([[-4.5110,  5.7411,  1.0059,  2.4664]])\n",
    "    fc2_bias = torch.tensor([0.8839])\n",
    "\n",
    "    x = torch.tensor([x1, x2]).float()\n",
    "    fc1_output = torch.sigmoid(torch.matmul(x, fc1_weight.transpose(0, 1)) + fc1_bias)\n",
    "    fc2_output = torch.sigmoid(torch.matmul(fc1_output, fc2_weight.transpose(0, 1)) + fc2_bias)\n",
    "\n",
    "    return fc2_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_diff(x1, x2):\n",
    "    weight = torch.tensor([[13.5223, 13.5223]])\n",
    "    bias = torch.tensor([-6.3024])\n",
    "    x = torch.tensor([x1, x2]).float()\n",
    "    output = torch.sigmoid(torch.matmul(x, weight.transpose(0, 1)) + bias)\n",
    "\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be float (each bit)\n",
    "def q_m_diff(input):\n",
    "    t_input = torch.tensor(input)\n",
    "    output = torch.tensor([t_input[0], 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    for bit in range(1, 8):\n",
    "        output[bit] = IndA_diff(t_input) * Real2Bit_diff(XNOR_diff(output[bit-1], t_input[bit])) + (1 - IndA_diff(t_input)) * Real2Bit_diff(XOR_diff(output[bit-1],t_input[bit]))\n",
    "    output[8] = 1 - IndA_diff(t_input)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.0005),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(1.0013),\n",
       "  tensor(0.0007),\n",
       "  tensor(1.),\n",
       "  tensor(0.9996)],\n",
       " tensor([0.9965]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TMDS_diff(pixel_bits,cnt):\n",
    "    bits_inversos = pixel_bits[::-1]\n",
    "    q_m = q_m_diff(bits_inversos)\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for bit in range(0,8):\n",
    "        output[bit] = q_m[bit] * OR_diff(IndB_diff(q_m[:8]),(1-IndC_diff(q_m[:8],cnt))) + NegBit_diff(q_m[bit]) * OR_diff((1 - IndB_diff(q_m[:8])),IndC_diff(q_m[:8],cnt))\n",
    "    output[8] = q_m[8]\n",
    "    output[9] = IndE_diff(q_m[:8],cnt) * NegBit_diff(q_m[8]) + (1 - IndE_diff(q_m[:8],cnt)) * IndC_diff(q_m[:8],cnt)\n",
    "    new_cnt = IndE_diff(q_m[:8],cnt) * ((cnt + torch.sum(q_m[:8] == 0).item() - torch.sum(q_m[:8] == 1).item()) * IndD_diff(q_m[:8]) + (cnt + torch.sum(q_m[:8] == 1).item() - torch.sum(q_m[:8] == 0).item()) * (1 -IndD_diff(q_m[:8]))) + (1 - IndE_diff(q_m[:8],cnt)) * ((cnt + 2 * q_m[8] + torch.sum(q_m[:8] == 0).item() - torch.sum(q_m[:8] == 1).item()) * IndC_diff(q_m[:8],cnt) + (cnt - 2 * NegBit_diff(q_m[8]) + torch.sum(q_m[:8] == 1).item() - torch.sum(q_m[:8] == 0).item()) * (1 - IndC_diff(q_m[:8],cnt)) )\n",
    "    return output,new_cnt\n",
    "\n",
    "pixel_bits = [1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "cnt=0\n",
    "TMDS_diff(pixel_bits,cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_simplified(input):\n",
    "   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pixel2Bit_diff(pixel):\n",
    "    output = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for i in range(1,9):\n",
    "        output[i-1] = 1 / (1 + np.exp(-(11*(pixel-2**(8-i)+0.5))))  #0.5 to adjust for the sigmoid so at 127.5 is at 0.5 and at 128 is already at 1\n",
    "        if pixel >= 2**(8-i):\n",
    "            pixel = pixel - 2**(8-i)\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
