{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de negación de un bit\n",
    "def negation_bit(x):\n",
    "    return int(not x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datos de entrenamiento y prueba\n",
    "# Datos de entrada (bits): 0, 1\n",
    "inputs = torch.tensor([[0], [1]], dtype=torch.float32)\n",
    "# Datos de salida (resultados de la función de negación de un bit): 1, 0\n",
    "labels = torch.tensor([[1], [0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red neuronal\n",
    "class SigmoidNegation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigmoidNegation, self).__init__() # super es para referirse a la clase padre nn.Module\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia de la red neuronal\n",
    "sigmoid_negation = SigmoidNegation()\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.BCELoss()   # para minimizar la función de pérdida de entropía cruzada binaria (BCELoss).\n",
    "optimizer = optim.SGD(sigmoid_negation.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Loss: 0.0051\n",
      "Epoch [1001/10000], Loss: 0.0046\n",
      "Epoch [2001/10000], Loss: 0.0042\n",
      "Epoch [3001/10000], Loss: 0.0039\n",
      "Epoch [4001/10000], Loss: 0.0036\n",
      "Epoch [5001/10000], Loss: 0.0034\n",
      "Epoch [6001/10000], Loss: 0.0032\n",
      "Epoch [7001/10000], Loss: 0.0030\n",
      "Epoch [8001/10000], Loss: 0.0028\n",
      "Epoch [9001/10000], Loss: 0.0027\n",
      "Epoch [10001/10000], Loss: 0.0025\n",
      "Epoch [11001/10000], Loss: 0.0024\n",
      "Epoch [12001/10000], Loss: 0.0023\n",
      "Epoch [13001/10000], Loss: 0.0022\n",
      "Epoch [14001/10000], Loss: 0.0021\n",
      "Epoch [15001/10000], Loss: 0.0020\n",
      "Epoch [16001/10000], Loss: 0.0019\n",
      "Epoch [17001/10000], Loss: 0.0019\n",
      "Epoch [18001/10000], Loss: 0.0018\n",
      "Epoch [19001/10000], Loss: 0.0017\n",
      "Epoch [20001/10000], Loss: 0.0017\n",
      "Epoch [21001/10000], Loss: 0.0016\n",
      "Epoch [22001/10000], Loss: 0.0016\n",
      "Epoch [23001/10000], Loss: 0.0015\n",
      "Epoch [24001/10000], Loss: 0.0015\n",
      "Epoch [25001/10000], Loss: 0.0014\n",
      "Epoch [26001/10000], Loss: 0.0014\n",
      "Epoch [27001/10000], Loss: 0.0014\n",
      "Epoch [28001/10000], Loss: 0.0013\n",
      "Epoch [29001/10000], Loss: 0.0013\n",
      "Epoch [30001/10000], Loss: 0.0013\n",
      "Epoch [31001/10000], Loss: 0.0012\n",
      "Epoch [32001/10000], Loss: 0.0012\n",
      "Epoch [33001/10000], Loss: 0.0012\n",
      "Epoch [34001/10000], Loss: 0.0011\n",
      "Epoch [35001/10000], Loss: 0.0011\n",
      "Epoch [36001/10000], Loss: 0.0011\n",
      "Epoch [37001/10000], Loss: 0.0011\n",
      "Epoch [38001/10000], Loss: 0.0010\n",
      "Epoch [39001/10000], Loss: 0.0010\n",
      "Epoch [40001/10000], Loss: 0.0010\n",
      "Epoch [41001/10000], Loss: 0.0010\n",
      "Epoch [42001/10000], Loss: 0.0010\n",
      "Epoch [43001/10000], Loss: 0.0009\n",
      "Epoch [44001/10000], Loss: 0.0009\n",
      "Epoch [45001/10000], Loss: 0.0009\n",
      "Epoch [46001/10000], Loss: 0.0009\n",
      "Epoch [47001/10000], Loss: 0.0009\n",
      "Epoch [48001/10000], Loss: 0.0009\n",
      "Epoch [49001/10000], Loss: 0.0009\n",
      "Epoch [50001/10000], Loss: 0.0008\n",
      "Epoch [51001/10000], Loss: 0.0008\n",
      "Epoch [52001/10000], Loss: 0.0008\n",
      "Epoch [53001/10000], Loss: 0.0008\n",
      "Epoch [54001/10000], Loss: 0.0008\n",
      "Epoch [55001/10000], Loss: 0.0008\n",
      "Epoch [56001/10000], Loss: 0.0008\n",
      "Epoch [57001/10000], Loss: 0.0007\n",
      "Epoch [58001/10000], Loss: 0.0007\n",
      "Epoch [59001/10000], Loss: 0.0007\n",
      "Epoch [60001/10000], Loss: 0.0007\n",
      "Epoch [61001/10000], Loss: 0.0007\n",
      "Epoch [62001/10000], Loss: 0.0007\n",
      "Epoch [63001/10000], Loss: 0.0007\n",
      "Epoch [64001/10000], Loss: 0.0007\n",
      "Epoch [65001/10000], Loss: 0.0007\n",
      "Epoch [66001/10000], Loss: 0.0007\n",
      "Epoch [67001/10000], Loss: 0.0007\n",
      "Epoch [68001/10000], Loss: 0.0006\n",
      "Epoch [69001/10000], Loss: 0.0006\n",
      "Epoch [70001/10000], Loss: 0.0006\n",
      "Epoch [71001/10000], Loss: 0.0006\n",
      "Epoch [72001/10000], Loss: 0.0006\n",
      "Epoch [73001/10000], Loss: 0.0006\n",
      "Epoch [74001/10000], Loss: 0.0006\n",
      "Epoch [75001/10000], Loss: 0.0006\n",
      "Epoch [76001/10000], Loss: 0.0006\n",
      "Epoch [77001/10000], Loss: 0.0006\n",
      "Epoch [78001/10000], Loss: 0.0006\n",
      "Epoch [79001/10000], Loss: 0.0006\n",
      "Epoch [80001/10000], Loss: 0.0006\n",
      "Epoch [81001/10000], Loss: 0.0006\n",
      "Epoch [82001/10000], Loss: 0.0005\n",
      "Epoch [83001/10000], Loss: 0.0005\n",
      "Epoch [84001/10000], Loss: 0.0005\n",
      "Epoch [85001/10000], Loss: 0.0005\n",
      "Epoch [86001/10000], Loss: 0.0005\n",
      "Epoch [87001/10000], Loss: 0.0005\n",
      "Epoch [88001/10000], Loss: 0.0005\n",
      "Epoch [89001/10000], Loss: 0.0005\n",
      "Epoch [90001/10000], Loss: 0.0005\n",
      "Epoch [91001/10000], Loss: 0.0005\n",
      "Epoch [92001/10000], Loss: 0.0005\n",
      "Epoch [93001/10000], Loss: 0.0005\n",
      "Epoch [94001/10000], Loss: 0.0005\n",
      "Epoch [95001/10000], Loss: 0.0005\n",
      "Epoch [96001/10000], Loss: 0.0005\n",
      "Epoch [97001/10000], Loss: 0.0005\n",
      "Epoch [98001/10000], Loss: 0.0005\n",
      "Epoch [99001/10000], Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = sigmoid_negation(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/10000], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: 0.0, Predicción: 1.0\n",
      "Entrada: 1.0, Predicción: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los resultados de la predicción\n",
    "with torch.no_grad():\n",
    "    predicted = sigmoid_negation(inputs)\n",
    "    predicted = np.round(predicted.numpy()) # Redondear a 0 o 1\n",
    "    for i in range(len(inputs)):\n",
    "        print(f'Entrada: {inputs[i].item()}, Predicción: {predicted[i].item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros de la red neuronal:\n",
      "Nombre del parámetro: fc.weight, Valor: Parameter containing:\n",
      "tensor([[-15.4261]], requires_grad=True)\n",
      "Nombre del parámetro: fc.bias, Valor: Parameter containing:\n",
      "tensor([7.5102], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Imprimir todos los parámetros de la red neuronal\n",
    "print(\"Parámetros de la red neuronal:\")\n",
    "for name, param in sigmoid_negation.named_parameters():\n",
    "    print(f'Nombre del parámetro: {name}, Valor: {param}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
