{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "#from joblib import Parallel, delayed  #multithreading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una red neuronal simple\n",
    "class Model_qm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_qm, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_m_XOR = Model_qm()\n",
    "state_dict_XOR = torch.load('q_m_XOR.pth')\n",
    "q_m_XOR.load_state_dict(state_dict_XOR)\n",
    "\n",
    "def q_m_XOR_diff(bits):\n",
    "    return q_m_XOR(bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_m_XNOR = Model_qm()\n",
    "state_dict_XNOR = torch.load('q_m_XNOR.pth')\n",
    "q_m_XNOR.load_state_dict(state_dict_XNOR)\n",
    "\n",
    "def q_m_XNOR_diff(bits):\n",
    "    return q_m_XNOR(bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_m_diff(input):\n",
    "    output = torch.zeros((input.shape[0],9), dtype=torch.float32)\n",
    "    all_ind_mask = torch.ones(input.shape[0], dtype=torch.bool)\n",
    "    num_1 = (input > 0.5).sum(dim=1)\n",
    "    #print(f\"num_1:{num_1}\")\n",
    "    num_1_plus4_mask = (num_1 > 4) # mask donde la suma de 1 es mayor a 4\n",
    "    #print(f\"num_1_plus4_mask: {num_1_plus4_mask}\")\n",
    "    num_1_equal4_mask = (num_1 == 4) # mask donde la suma de 1 es 4\n",
    "    #print(f\"num_1_equal4_mask:{num_1_equal4_mask}\")                      \n",
    "    data0_equal0_mask = (input[:,0] == 0) # mask donde el primer valor de la entrada es 0\n",
    "    #print(f\"data0_equal0_mask:{data0_equal0_mask}\")  \n",
    "    intersect_ind_mask = (data0_equal0_mask == num_1_equal4_mask) # mask donde el primer valor de la entrada es 0 y la suma de 1 es 4\n",
    "    #print(f\"intersect_ind_mask 1:{intersect_ind_mask}\")   \n",
    "    intersect_ind_mask = (intersect_ind_mask | num_1_plus4_mask)  # mask donde: (el primer valor de la entrada es 0 y la suma de 1 es 4) OR (la suma es mayor a 4)\n",
    "    #print(f\"intersect_ind_mask 2:{intersect_ind_mask}\")   \n",
    "    intersect_ind = intersect_ind_mask.nonzero().squeeze()  # posiciones donde: (el primer valor de la entrada es 0 y la suma de 1 es 4) OR (la suma es mayor a 4)\n",
    "    #print(f\"intersect_ind:{intersect_ind}\")   \n",
    "    rest_ind = (intersect_ind_mask != all_ind_mask).nonzero().squeeze() #resto de indices que no cumplen condiciones anteriores\n",
    "    #print(f\"rest_ind:{rest_ind}\")\n",
    "\n",
    "    output[intersect_ind,:8] = q_m_XNOR_diff(input[intersect_ind,:])\n",
    "    output[intersect_ind,8] = 0\n",
    "    output[rest_ind,:8] = q_m_XOR_diff(input[rest_ind,:])\n",
    "    output[rest_ind,8] = 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMDS_diff(pixel_column_bits,cnt_column):\n",
    "    bits_inversos = torch.flip(pixel_column_bits, dims = (1,))  #ahora es en la dim = 1 y no 0\n",
    "    q_m = q_m_diff(bits_inversos)\n",
    "    print(f\"qm_diff:{torch.round(q_m)}\")\n",
    "    output = torch.zeros((pixel_column_bits.shape[0],10),dtype=torch.float32)\n",
    "    num_1 = (q_m[:,:8] > 0.5).sum(dim = 1)\n",
    "    num_0 = (q_m[:,:8] < 0.5).sum(dim = 1)\n",
    "    #print(f\"num1:{num_1}\")\n",
    "    #print(f\"num0:{num_0}\")\n",
    "    all_ind_mask = torch.ones(q_m.shape[0], dtype=torch.bool)\n",
    "    IndE_mask = (cnt_column == 0) | (num_1 == num_0)\n",
    "    #print(f\"IndE_mask:{IndE_mask}\")\n",
    "    IndE_ind = ((cnt_column == 0) | (num_1 == num_0)).nonzero().squeeze()\n",
    "    #print(f\"IndE_ind:{IndE_ind}\")\n",
    "    IndC_mask = ((cnt_column > 0) &  (num_1 > num_0)) & ((cnt_column < 0) & (num_0 > num_1))\n",
    "    #print(f\"IndC_mask:{IndC_mask}\")\n",
    "    Neg_q = 1 - q_m\n",
    "    #print(f\"Neg_qm_diff:{torch.round(Neg_q)}\")\n",
    "    IndE_and_q_m_0 = ((IndE_mask) & (q_m[:,8] < 0.5)).nonzero().squeeze()\n",
    "    #print(f\"IndE_and_q_m_0:{IndE_and_q_m_0}\")\n",
    "    IndE_and_q_m_1 = ((IndE_mask) & (q_m[:,8] > 0.5)).nonzero().squeeze()\n",
    "    #print(f\"IndE_and_q_m_1:{IndE_and_q_m_1}\")\n",
    "    NotIndE_and_IndC = (torch.logical_not(IndE_mask) & IndC_mask).nonzero().squeeze()\n",
    "    #print(f\"NotIndE_and_IndC:{NotIndE_and_IndC}\")\n",
    "    NotIndE_and_NotIndC = (torch.logical_not(IndE_mask) & torch.logical_not(IndC_mask)).nonzero().squeeze()\n",
    "    #print(f\"NotIndE_and_NotIndC:{NotIndE_and_NotIndC}\")\n",
    "    q_m_mask = (IndE_mask & (q_m[:,8] > 0.5)) | (torch.logical_not(IndC_mask) & torch.logical_not(IndE_mask))\n",
    "    #print(f\"q_m_mask:{q_m_mask}\")\n",
    "    q_m_ind = ((IndE_mask & (q_m[:,8] > 0.5)) | (torch.logical_not(IndC_mask) & torch.logical_not(IndE_mask))).nonzero().squeeze()\n",
    "    #print(f\"q_m_ind:{q_m_ind}\")\n",
    "    Neg_q_ind = (q_m_mask != all_ind_mask).nonzero().squeeze()\n",
    "    #print(f\"Neg_q_ind:{Neg_q_ind}\")\n",
    "    output[q_m_ind,:8] = q_m[q_m_ind,:8]\n",
    "    output[Neg_q_ind,:8] = Neg_q[Neg_q_ind,:8]\n",
    "    output[:,8] = q_m[:,8]\n",
    "    output[IndE_ind,9] = Neg_q[IndE_ind,8]\n",
    "    new_cnt = cnt_column.clone()\n",
    "    new_cnt[IndE_and_q_m_0] = cnt_column[IndE_and_q_m_0] + num_0[IndE_and_q_m_0] - num_1[IndE_and_q_m_0]\n",
    "    new_cnt[IndE_and_q_m_1] = cnt_column[IndE_and_q_m_1] + num_1[IndE_and_q_m_1] - num_0[IndE_and_q_m_1]\n",
    "    #print(f\"new_cnt:{new_cnt}\")\n",
    "    output[NotIndE_and_IndC,9] = 1\n",
    "    new_cnt[NotIndE_and_IndC] = cnt_column[NotIndE_and_IndC] + 2 * q_m[NotIndE_and_IndC,8] + num_0[NotIndE_and_IndC] - num_1[NotIndE_and_IndC]\n",
    "    #print(f\"new_cnt:{new_cnt}\")\n",
    "    output[NotIndE_and_NotIndC,9] = 0\n",
    "    new_cnt[NotIndE_and_NotIndC] = cnt_column[NotIndE_and_NotIndC] - 2 * Neg_q[NotIndE_and_NotIndC,8] + num_1[NotIndE_and_NotIndC] - num_0[NotIndE_and_NotIndC]\n",
    "    #print(f\"new_cnt:{new_cnt}\")\n",
    "\n",
    "    return output,new_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.zeros((2,8))\n",
    "batch[0,:] = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
    "batch[1,:] = torch.tensor([1, 0, 0, 0, 0, 0, 1, 1])\n",
    "cnt_column = torch.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qm_diff:tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 0., 1., 0., 1., 0., 0., 0.]], grad_fn=<RoundBackward0>)\n",
      "num1:tensor([0, 4])\n",
      "num0:tensor([8, 4])\n",
      "IndE_mask:tensor([True, True])\n",
      "IndE_ind:tensor([0, 1])\n",
      "IndC_mask:tensor([False, False])\n",
      "Neg_qm_diff:tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 1., 1.]], grad_fn=<RoundBackward0>)\n",
      "IndE_and_q_m_0:1\n",
      "IndE_and_q_m_1:0\n",
      "NotIndE_and_IndC:tensor([], dtype=torch.int64)\n",
      "NotIndE_and_NotIndC:tensor([], dtype=torch.int64)\n",
      "q_m_mask:tensor([ True, False])\n",
      "q_m_ind:0\n",
      "Neg_q_ind:1\n",
      "new_cnt:tensor([-8.,  0.])\n",
      "new_cnt:tensor([-8.,  0.], grad_fn=<IndexPutBackward0>)\n",
      "new_cnt:tensor([-8.,  0.], grad_fn=<IndexPutBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 1., 1., 0., 1.]], grad_fn=<RoundBackward0>)\n",
      "tensor([-8.,  0.], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out,cnt = TMDS_diff(batch,cnt_column)\n",
    "print(torch.round(out))\n",
    "print(torch.round(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x_in = x.clone()\n",
    "    if x >= 0:\n",
    "        return 1 / (1 + torch.exp(-x_in))\n",
    "    else:\n",
    "        return torch.exp(x_in) / (1 + torch.exp(x_in))\n",
    "\n",
    "def Pixel2Bit_diff(pixel):\n",
    "    output = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0], dtype= torch.float32)\n",
    "    for i in range(1,9):\n",
    "        output[i-1] = sigmoid(10*(pixel-2**(8-i)+0.5))  # 0.5 para ajustar la sigmoidal\n",
    "        if pixel >= 2**(8-i):\n",
    "            pixel = pixel - 2**(8-i)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que toma como entrada el armonico a sintonizar y las dimensiones de la imagen a espiar y devuelve un array con taps de g(t)\n",
    "def g_taps(dim_vertical, dim_horizontal, armonico):\n",
    "\n",
    "    #defino variables iniciales\n",
    "    f_b = 10 * (dim_vertical * dim_horizontal * 60)\n",
    "    f_sdr = 50e6\n",
    "    harm = armonico * f_b\n",
    "    \n",
    "    #para el correcto funcionamiento: dependiendo del armonico, elijo cuantas muestras por pulso\n",
    "    if (armonico < 5 ):\n",
    "        muestras_por_pulso  = 10\n",
    "    else:\n",
    "        muestras_por_pulso  = 20\n",
    "\n",
    "    samp_rate = muestras_por_pulso * f_b\n",
    "    H_samples = dim_horizontal * muestras_por_pulso\n",
    "\n",
    "    #creo el pulso\n",
    "    t_continuous = np.linspace(start = 0, stop = H_samples/samp_rate, num = H_samples, endpoint= False)\n",
    "    pulso = np.zeros(H_samples)\n",
    "    pulso[:muestras_por_pulso] = 1\n",
    "\n",
    "    #traslado el espectro del pulso el armonico correspondiente\n",
    "    frec_armonico = np.exp(-2j*np.pi*harm*t_continuous)\n",
    "    pulso_complejo = pulso*frec_armonico\n",
    "\n",
    "    #creo el lpf del sdr\n",
    "    b, a = signal.butter(6, f_sdr/2, fs=samp_rate, btype='lowpass', analog=False)\n",
    "\n",
    "    #filtro con lpf el pulso multiplicado por armonico. El resultado es g\n",
    "    g_t = signal.lfilter(b, a, pulso_complejo)\n",
    "    g_t = signal.decimate(g_t,q = muestras_por_pulso)\n",
    "\n",
    "    # si armonico crece, necesito mas taps\n",
    "    if (armonico < 5):\n",
    "        g_t = g_t[:30]\n",
    "    else:\n",
    "        g_t = g_t[:200]\n",
    "\n",
    "    g_t_max = np.max(np.abs(g_t))\n",
    " \n",
    "    g_t = g_t / g_t_max\n",
    "\n",
    "    return torch.tensor(g_t,dtype = torch.complex64).reshape(1,1,len(g_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(filas,columnas,g_t,padding,img_slice):\n",
    "    cnt_column = torch.zeros(filas)\n",
    "    pixels_column = torch.zeros(filas)\n",
    "    pixel_column_bits = torch.zeros((img_slice[0],8),dtype = torch.float32)\n",
    "    bits_cod_fila =  torch.zeros((img_slice.shape[0],1,10*columnas), dtype = torch.complex64)\n",
    "    for j in range(columnas):\n",
    "        pixels_column = img_slice[:,j]\n",
    "        pixel_column_bits = Pixel2Bit_diff(pixels_column)\n",
    "        bits_cod_fila[:,:,j*10:(j+1)*10],cnt_column[:] = TMDS_diff(pixel_column_bits, cnt_column)\n",
    "    img_slice_out = nn.functional.conv1d(bits_cod_fila, g_t, stride = 10, padding=padding, bias = None)[:,:,:].reshape(filas,columnas)\n",
    "    return img_slice_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../../images/VAMO!!.png'\n",
    "img = np.asarray(Image.open(image_path))[:,:,0] #solo canal rojo\n",
    "img_slice = torch.tensor(img[:10,:], dtype=torch.float32, requires_grad=True)\n",
    "armonico = 3\n",
    "g_t = g_taps(img.shape, armonico)\n",
    "size_g_t = g_t.numel()    \n",
    "padding = (size_g_t - 10)//2\n",
    "imagen_fila_salida = forward(250,g_t,padding,img_slice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
