23-03-29 19:59:04.706 :   task: drunet
  model: plain
  gpu_ids: [0]
  scale: 1
  n_channels: 1
  n_channels_datasetload: 3
  sigma: [0, 50]
  sigma_test: 25
  path:[
    root: denoising
    pretrained_netG: denoising/drunet/models/1560_G.pth
    task: denoising/drunet
    log: denoising/drunet
    options: denoising/drunet/options
    models: denoising/drunet/models
    images: denoising/drunet/images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: ffdnet
      dataroot_H: trainsets/web_images_train
      num_patches_per_image: 10
      dataroot_L: trainsets/simulations
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 64
      phase: train
      scale: 1
      n_channels: 1
    ]
    test:[
      name: test_dataset
      dataset_type: ffdnet
      dataroot_H: testsets/web_images_test
      dataroot_L: testsets/simulations
      phase: test
      scale: 1
      n_channels: 1
    ]
  ]
  netG:[
    net_type: drunet
    in_nc: 1
    out_nc: 1
    nc: [64, 128, 256, 512]
    nb: 4
    gc: 32
    ng: 2
    reduction: 16
    act_mode: R
    upsample_mode: convtranspose
    downsample_mode: strideconv
    bias: False
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 1
  ]
  train:[
    epochs: 1000
    G_lossfn_type: tv
    G_lossfn_weight: 1.0
    G_tvloss_weight: 0.001
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [100000, 200000, 300000, 400000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 32
    checkpoint_save: 32
    checkpoint_print: 16
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
    G_optimizer_wd: 0
    G_optimizer_reuse: False
    G_param_strict: True
    E_param_strict: True
    E_decay: 0
  ]
  opt_path: options/train_drunet.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

23-03-29 19:59:04.711 : Number of train images: 500, iters: 8
23-03-29 19:59:05.542 : 
Networks name: UNetRes
Params number: 32638080
Net structure:
UNetRes(
  (m_head): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (m_down1): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)

23-03-29 19:59:05.560 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.000 | -0.074 |  0.076 |  0.025 | torch.Size([64, 1, 3, 3]) || m_head.weight
 |  0.000 | -0.033 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.0.res.0.weight
 |  0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.0.res.2.weight
 |  0.000 | -0.077 |  0.041 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.1.res.0.weight
 |  0.000 | -0.056 |  0.061 |  0.009 | torch.Size([64, 64, 3, 3]) || m_down1.1.res.2.weight
 |  0.000 | -0.044 |  0.046 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.2.res.0.weight
 |  0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.2.res.2.weight
 |  0.000 | -0.070 |  0.068 |  0.009 | torch.Size([64, 64, 3, 3]) || m_down1.3.res.0.weight
 |  0.000 | -0.068 |  0.065 |  0.009 | torch.Size([64, 64, 3, 3]) || m_down1.3.res.2.weight
 |  0.000 | -0.055 |  0.049 |  0.013 | torch.Size([128, 64, 2, 2]) || m_down1.4.weight
 | -0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.0.res.0.weight
 | -0.000 | -0.033 |  0.037 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.0.res.2.weight
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.1.res.0.weight
 | -0.000 | -0.029 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.1.res.2.weight
 | -0.000 | -0.040 |  0.048 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.2.res.0.weight
 |  0.000 | -0.068 |  0.052 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.2.res.2.weight
 | -0.000 | -0.049 |  0.089 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.3.res.0.weight
 |  0.000 | -0.067 |  0.069 |  0.007 | torch.Size([128, 128, 3, 3]) || m_down2.3.res.2.weight
 | -0.000 | -0.041 |  0.038 |  0.009 | torch.Size([256, 128, 2, 2]) || m_down2.4.weight
 |  0.000 | -0.047 |  0.036 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.0.res.0.weight
 |  0.000 | -0.021 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.0.res.2.weight
 |  0.000 | -0.022 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.1.res.0.weight
 |  0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.1.res.2.weight
 |  0.000 | -0.023 |  0.063 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.2.res.0.weight
 |  0.000 | -0.052 |  0.050 |  0.005 | torch.Size([256, 256, 3, 3]) || m_down3.2.res.2.weight
 |  0.000 | -0.039 |  0.048 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.3.res.0.weight
 |  0.000 | -0.070 |  0.068 |  0.005 | torch.Size([256, 256, 3, 3]) || m_down3.3.res.2.weight
 |  0.000 | -0.029 |  0.029 |  0.006 | torch.Size([512, 256, 2, 2]) || m_down3.4.weight
 |  0.000 | -0.028 |  0.027 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.0.res.0.weight
 |  0.000 | -0.016 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.0.res.2.weight
 |  0.000 | -0.046 |  0.042 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.1.res.0.weight
 |  0.000 | -0.042 |  0.054 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.1.res.2.weight
 |  0.000 | -0.044 |  0.077 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.2.res.0.weight
 |  0.000 | -0.072 |  0.090 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.2.res.2.weight
 |  0.000 | -0.033 |  0.039 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.3.res.0.weight
 |  0.000 | -0.135 |  0.149 |  0.004 | torch.Size([512, 512, 3, 3]) || m_body.3.res.2.weight
 | -0.000 | -0.028 |  0.027 |  0.006 | torch.Size([512, 256, 2, 2]) || m_up3.0.weight
 |  0.000 | -0.064 |  0.090 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.1.res.0.weight
 | -0.000 | -0.115 |  0.123 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.1.res.2.weight
 |  0.000 | -0.021 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.2.res.0.weight
 | -0.000 | -0.022 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.2.res.2.weight
 |  0.000 | -0.022 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.3.res.0.weight
 | -0.000 | -0.020 |  0.023 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.3.res.2.weight
 |  0.000 | -0.020 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.4.res.0.weight
 | -0.000 | -0.033 |  0.040 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.4.res.2.weight
 | -0.000 | -0.036 |  0.039 |  0.009 | torch.Size([256, 128, 2, 2]) || m_up2.0.weight
 |  0.000 | -0.030 |  0.047 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.1.res.0.weight
 |  0.000 | -0.125 |  0.113 |  0.008 | torch.Size([128, 128, 3, 3]) || m_up2.1.res.2.weight
 |  0.000 | -0.027 |  0.037 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.2.res.0.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.2.res.2.weight
 |  0.000 | -0.033 |  0.035 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.3.res.0.weight
 |  0.000 | -0.028 |  0.030 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.3.res.2.weight
 |  0.000 | -0.031 |  0.043 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.4.res.0.weight
 |  0.000 | -0.091 |  0.095 |  0.007 | torch.Size([128, 128, 3, 3]) || m_up2.4.res.2.weight
 | -0.000 | -0.050 |  0.049 |  0.013 | torch.Size([128, 64, 2, 2]) || m_up1.0.weight
 | -0.000 | -0.044 |  0.047 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.1.res.0.weight
 |  0.000 | -0.081 |  0.085 |  0.010 | torch.Size([64, 64, 3, 3]) || m_up1.1.res.2.weight
 |  0.000 | -0.052 |  0.043 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.2.res.0.weight
 |  0.000 | -0.056 |  0.048 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.2.res.2.weight
 | -0.000 | -0.053 |  0.058 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.3.res.0.weight
 | -0.000 | -0.134 |  0.134 |  0.018 | torch.Size([64, 64, 3, 3]) || m_up1.3.res.2.weight
 |  0.000 | -0.054 |  0.040 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.4.res.0.weight
 | -0.000 | -0.062 |  0.067 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.4.res.2.weight
 | -0.000 | -0.029 |  0.022 |  0.008 | torch.Size([1, 64, 3, 3]) || m_tail.weight

23-03-29 19:59:13.288 : <epoch:  1, iter:   1,568, lr:1.000e-04> G_loss: 2.968e-02 
23-03-29 19:59:13.288 : Saving the model.
23-03-29 19:59:13.854 : ---1-->  10094.png | 10.27dB
23-03-29 19:59:14.161 : ---2-->  10231.png | 9.88dB
23-03-29 19:59:14.474 : ---3-->   1037.png | 10.16dB
23-03-29 19:59:14.780 : ---4-->  10379.png | 10.24dB
23-03-29 19:59:15.098 : ---5-->  10420.png | 10.60dB
23-03-29 19:59:15.404 : ---6-->  10436.png | 10.17dB
23-03-29 19:59:15.705 : ---7-->  10534.png | 11.41dB
23-03-29 19:59:16.010 : ---8-->  11054.png | 10.10dB
23-03-29 19:59:16.332 : ---9-->  11143.png | 9.95dB
23-03-29 19:59:16.633 : --10-->  11294.png | 10.02dB
23-03-29 19:59:16.950 : --11-->  11404.png | 10.06dB
23-03-29 19:59:17.260 : --12-->  11604.png | 10.11dB
23-03-29 19:59:17.586 : --13-->  11708.png | 9.98dB
23-03-29 19:59:17.901 : --14-->  11712.png | 9.91dB
23-03-29 19:59:18.211 : --15-->  11880.png | 10.21dB
23-03-29 19:59:18.524 : --16-->   1190.png | 9.84dB
23-03-29 19:59:18.845 : --17-->  12009.png | 9.89dB
23-03-29 19:59:19.148 : --18-->  12248.png | 9.97dB
23-03-29 19:59:19.455 : --19-->  12449.png | 10.85dB
23-03-29 19:59:19.759 : --20-->  12460.png | 10.02dB
23-03-29 19:59:20.076 : --21-->    125.png | 10.07dB
23-03-29 19:59:20.384 : --22-->  12539.png | 9.96dB
23-03-29 19:59:20.686 : --23-->    134.png | 10.03dB
23-03-29 19:59:20.991 : --24-->  13450.png | 9.89dB
23-03-29 19:59:21.311 : --25-->  13902.png | 10.31dB
23-03-29 19:59:21.611 : --26-->  14107.png | 9.95dB
23-03-29 19:59:21.918 : --27-->   1421.png | 9.83dB
23-03-29 19:59:22.223 : --28-->  14305.png | 9.80dB
23-03-29 19:59:22.544 : --29-->   1431.png | 10.12dB
23-03-29 19:59:22.853 : --30-->  14926.png | 10.03dB
23-03-29 19:59:23.158 : --31-->  15307.png | 10.02dB
23-03-29 19:59:23.468 : --32-->  15387.png | 10.09dB
23-03-29 19:59:23.791 : --33-->  15612.png | 9.91dB
23-03-29 19:59:24.094 : --34-->  15661.png | 10.07dB
23-03-29 19:59:24.402 : --35-->  15681.png | 10.17dB
23-03-29 19:59:24.716 : --36-->    159.png | 9.83dB
23-03-29 19:59:25.043 : --37-->  15930.png | 10.12dB
23-03-29 19:59:25.363 : --38-->  16028.png | 10.16dB
23-03-29 19:59:25.666 : --39-->   1619.png | 10.02dB
23-03-29 19:59:25.980 : --40-->    168.png | 11.83dB
23-03-29 19:59:26.303 : --41-->    174.png | 10.07dB
23-03-29 19:59:26.616 : --42-->    188.png | 10.04dB
23-03-29 19:59:26.927 : --43-->   1928.png | 10.12dB
23-03-29 19:59:27.234 : --44-->   1942.png | 9.94dB
23-03-29 19:59:27.557 : --45-->    209.png | 10.06dB
23-03-29 19:59:27.870 : --46-->   2179.png | 10.11dB
23-03-29 19:59:28.176 : --47-->   2541.png | 10.20dB
23-03-29 19:59:28.485 : --48-->   3164.png | 9.91dB
23-03-29 19:59:28.809 : --49-->   3259.png | 9.85dB
23-03-29 19:59:29.111 : --50-->   3410.png | 10.12dB
23-03-29 19:59:29.126 : <epoch:  1, iter:   1,568, Average PSNR : 10.13dB

23-03-29 20:01:45.370 :   task: drunet
  model: plain
  gpu_ids: [0]
  scale: 1
  n_channels: 1
  n_channels_datasetload: 3
  sigma: [0, 50]
  sigma_test: 25
  path:[
    root: denoising
    pretrained_netG: denoising/drunet/models/1560_G.pth
    task: denoising/drunet
    log: denoising/drunet
    options: denoising/drunet/options
    models: denoising/drunet/models
    images: denoising/drunet/images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: ffdnet
      dataroot_H: trainsets/web_images_train
      num_patches_per_image: 10
      dataroot_L: trainsets/simulations
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 64
      phase: train
      scale: 1
      n_channels: 1
    ]
    test:[
      name: test_dataset
      dataset_type: ffdnet
      dataroot_H: testsets/web_images_test
      dataroot_L: testsets/simulations
      phase: test
      scale: 1
      n_channels: 1
    ]
  ]
  netG:[
    net_type: drunet
    in_nc: 3
    out_nc: 3
    nc: [64, 128, 256, 512]
    nb: 4
    gc: 32
    ng: 2
    reduction: 16
    act_mode: R
    upsample_mode: convtranspose
    downsample_mode: strideconv
    bias: False
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 1
  ]
  train:[
    epochs: 1000
    G_lossfn_type: tv
    G_lossfn_weight: 1.0
    G_tvloss_weight: 0.001
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [100000, 200000, 300000, 400000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 400
    checkpoint_save: 800
    checkpoint_print: 16
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
    G_optimizer_wd: 0
    G_optimizer_reuse: False
    G_param_strict: True
    E_param_strict: True
    E_decay: 0
  ]
  opt_path: options/train_drunet.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

23-03-29 20:01:45.374 : Number of train images: 500, iters: 8
23-03-29 20:02:59.813 :   task: drunet
  model: plain
  gpu_ids: [0]
  scale: 1
  n_channels: 1
  n_channels_datasetload: 3
  sigma: [0, 50]
  sigma_test: 25
  path:[
    root: denoising
    pretrained_netG: denoising/drunet/models/1560_G.pth
    task: denoising/drunet
    log: denoising/drunet
    options: denoising/drunet/options
    models: denoising/drunet/models
    images: denoising/drunet/images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: ffdnet
      dataroot_H: trainsets/web_images_train
      num_patches_per_image: 10
      dataroot_L: trainsets/simulations
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 64
      phase: train
      scale: 1
      n_channels: 1
    ]
    test:[
      name: test_dataset
      dataset_type: ffdnet
      dataroot_H: testsets/web_images_test
      dataroot_L: testsets/simulations
      phase: test
      scale: 1
      n_channels: 1
    ]
  ]
  netG:[
    net_type: drunet
    in_nc: 1
    out_nc: 1
    nc: [64, 128, 256, 512]
    nb: 4
    gc: 32
    ng: 2
    reduction: 16
    act_mode: R
    upsample_mode: convtranspose
    downsample_mode: strideconv
    bias: False
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 1
  ]
  train:[
    epochs: 1000
    G_lossfn_type: tv
    G_lossfn_weight: 1.0
    G_tvloss_weight: 0.001
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [100000, 200000, 300000, 400000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 400
    checkpoint_save: 800
    checkpoint_print: 16
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
    G_optimizer_wd: 0
    G_optimizer_reuse: False
    G_param_strict: True
    E_param_strict: True
    E_decay: 0
  ]
  opt_path: options/train_drunet.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

23-03-29 20:02:59.816 : Number of train images: 500, iters: 8
23-03-29 20:03:00.640 : 
Networks name: UNetRes
Params number: 32638080
Net structure:
UNetRes(
  (m_head): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (m_down1): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)

23-03-29 20:03:00.658 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.000 | -0.074 |  0.076 |  0.025 | torch.Size([64, 1, 3, 3]) || m_head.weight
 |  0.000 | -0.033 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.0.res.0.weight
 |  0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.0.res.2.weight
 |  0.000 | -0.077 |  0.041 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.1.res.0.weight
 |  0.000 | -0.056 |  0.061 |  0.009 | torch.Size([64, 64, 3, 3]) || m_down1.1.res.2.weight
 |  0.000 | -0.044 |  0.046 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.2.res.0.weight
 |  0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.2.res.2.weight
 |  0.000 | -0.070 |  0.068 |  0.009 | torch.Size([64, 64, 3, 3]) || m_down1.3.res.0.weight
 |  0.000 | -0.068 |  0.065 |  0.009 | torch.Size([64, 64, 3, 3]) || m_down1.3.res.2.weight
 |  0.000 | -0.055 |  0.049 |  0.013 | torch.Size([128, 64, 2, 2]) || m_down1.4.weight
 | -0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.0.res.0.weight
 | -0.000 | -0.033 |  0.037 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.0.res.2.weight
 | -0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.1.res.0.weight
 | -0.000 | -0.029 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.1.res.2.weight
 | -0.000 | -0.040 |  0.048 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.2.res.0.weight
 |  0.000 | -0.068 |  0.052 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.2.res.2.weight
 | -0.000 | -0.049 |  0.089 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.3.res.0.weight
 |  0.000 | -0.067 |  0.069 |  0.007 | torch.Size([128, 128, 3, 3]) || m_down2.3.res.2.weight
 | -0.000 | -0.041 |  0.038 |  0.009 | torch.Size([256, 128, 2, 2]) || m_down2.4.weight
 |  0.000 | -0.047 |  0.036 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.0.res.0.weight
 |  0.000 | -0.021 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.0.res.2.weight
 |  0.000 | -0.022 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.1.res.0.weight
 |  0.000 | -0.021 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.1.res.2.weight
 |  0.000 | -0.023 |  0.063 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.2.res.0.weight
 |  0.000 | -0.052 |  0.050 |  0.005 | torch.Size([256, 256, 3, 3]) || m_down3.2.res.2.weight
 |  0.000 | -0.039 |  0.048 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.3.res.0.weight
 |  0.000 | -0.070 |  0.068 |  0.005 | torch.Size([256, 256, 3, 3]) || m_down3.3.res.2.weight
 |  0.000 | -0.029 |  0.029 |  0.006 | torch.Size([512, 256, 2, 2]) || m_down3.4.weight
 |  0.000 | -0.028 |  0.027 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.0.res.0.weight
 |  0.000 | -0.016 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.0.res.2.weight
 |  0.000 | -0.046 |  0.042 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.1.res.0.weight
 |  0.000 | -0.042 |  0.054 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.1.res.2.weight
 |  0.000 | -0.044 |  0.077 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.2.res.0.weight
 |  0.000 | -0.072 |  0.090 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.2.res.2.weight
 |  0.000 | -0.033 |  0.039 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.3.res.0.weight
 |  0.000 | -0.135 |  0.149 |  0.004 | torch.Size([512, 512, 3, 3]) || m_body.3.res.2.weight
 | -0.000 | -0.028 |  0.027 |  0.006 | torch.Size([512, 256, 2, 2]) || m_up3.0.weight
 |  0.000 | -0.064 |  0.090 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.1.res.0.weight
 | -0.000 | -0.115 |  0.123 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.1.res.2.weight
 |  0.000 | -0.021 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.2.res.0.weight
 | -0.000 | -0.022 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.2.res.2.weight
 |  0.000 | -0.022 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.3.res.0.weight
 | -0.000 | -0.020 |  0.023 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.3.res.2.weight
 |  0.000 | -0.020 |  0.022 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.4.res.0.weight
 | -0.000 | -0.033 |  0.040 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.4.res.2.weight
 | -0.000 | -0.036 |  0.039 |  0.009 | torch.Size([256, 128, 2, 2]) || m_up2.0.weight
 |  0.000 | -0.030 |  0.047 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.1.res.0.weight
 |  0.000 | -0.125 |  0.113 |  0.008 | torch.Size([128, 128, 3, 3]) || m_up2.1.res.2.weight
 |  0.000 | -0.027 |  0.037 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.2.res.0.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.2.res.2.weight
 |  0.000 | -0.033 |  0.035 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.3.res.0.weight
 |  0.000 | -0.028 |  0.030 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.3.res.2.weight
 |  0.000 | -0.031 |  0.043 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.4.res.0.weight
 |  0.000 | -0.091 |  0.095 |  0.007 | torch.Size([128, 128, 3, 3]) || m_up2.4.res.2.weight
 | -0.000 | -0.050 |  0.049 |  0.013 | torch.Size([128, 64, 2, 2]) || m_up1.0.weight
 | -0.000 | -0.044 |  0.047 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.1.res.0.weight
 |  0.000 | -0.081 |  0.085 |  0.010 | torch.Size([64, 64, 3, 3]) || m_up1.1.res.2.weight
 |  0.000 | -0.052 |  0.043 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.2.res.0.weight
 |  0.000 | -0.056 |  0.048 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.2.res.2.weight
 | -0.000 | -0.053 |  0.058 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.3.res.0.weight
 | -0.000 | -0.134 |  0.134 |  0.018 | torch.Size([64, 64, 3, 3]) || m_up1.3.res.2.weight
 |  0.000 | -0.054 |  0.040 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.4.res.0.weight
 | -0.000 | -0.062 |  0.067 |  0.009 | torch.Size([64, 64, 3, 3]) || m_up1.4.res.2.weight
 | -0.000 | -0.029 |  0.022 |  0.008 | torch.Size([1, 64, 3, 3]) || m_tail.weight

23-03-29 20:03:08.384 : <epoch:  1, iter:   1,568, lr:1.000e-04> G_loss: 2.642e-02 
23-03-29 20:03:20.531 : <epoch:  3, iter:   1,584, lr:1.000e-04> G_loss: 4.265e-02 
23-03-29 20:03:32.799 : <epoch:  5, iter:   1,600, lr:1.000e-04> G_loss: 2.515e-02 
23-03-29 20:03:32.799 : Saving the model.
23-03-29 20:03:33.357 : ---1-->  10094.png | 17.07dB
23-03-29 20:03:33.660 : ---2-->  10231.png | 19.69dB
23-03-29 20:03:33.969 : ---3-->   1037.png | 18.88dB
23-03-29 20:03:34.281 : ---4-->  10379.png | 17.15dB
23-03-29 20:03:34.602 : ---5-->  10420.png | 21.80dB
23-03-29 20:03:34.912 : ---6-->  10436.png | 18.69dB
23-03-29 20:03:35.220 : ---7-->  10534.png | 17.80dB
23-03-29 20:03:35.527 : ---8-->  11054.png | 20.59dB
23-03-29 20:03:35.853 : ---9-->  11143.png | 18.02dB
23-03-29 20:03:36.157 : --10-->  11294.png | 20.05dB
23-03-29 20:03:36.469 : --11-->  11404.png | 18.18dB
23-03-29 20:03:36.780 : --12-->  11604.png | 17.86dB
23-03-29 20:03:37.101 : --13-->  11708.png | 17.71dB
23-03-29 20:03:37.413 : --14-->  11712.png | 17.47dB
23-03-29 20:03:37.722 : --15-->  11880.png | 19.14dB
23-03-29 20:03:38.027 : --16-->   1190.png | 17.18dB
23-03-29 20:03:38.352 : --17-->  12009.png | 17.64dB
23-03-29 20:03:38.654 : --18-->  12248.png | 18.99dB
23-03-29 20:03:38.965 : --19-->  12449.png | 17.18dB
23-03-29 20:03:39.275 : --20-->  12460.png | 18.86dB
23-03-29 20:03:39.595 : --21-->    125.png | 20.53dB
23-03-29 20:03:39.906 : --22-->  12539.png | 17.97dB
23-03-29 20:03:40.214 : --23-->    134.png | 18.66dB
23-03-29 20:03:40.524 : --24-->  13450.png | 18.38dB
23-03-29 20:03:40.853 : --25-->  13902.png | 18.72dB
23-03-29 20:03:41.158 : --26-->  14107.png | 20.17dB
23-03-29 20:03:41.469 : --27-->   1421.png | 17.75dB
23-03-29 20:03:41.780 : --28-->  14305.png | 18.27dB
23-03-29 20:03:42.101 : --29-->   1431.png | 17.36dB
23-03-29 20:03:42.416 : --30-->  14926.png | 16.63dB
23-03-29 20:03:42.724 : --31-->  15307.png | 18.90dB
23-03-29 20:03:43.031 : --32-->  15387.png | 18.61dB
23-03-29 20:03:43.358 : --33-->  15612.png | 17.73dB
23-03-29 20:03:43.663 : --34-->  15661.png | 17.78dB
23-03-29 20:03:43.974 : --35-->  15681.png | 17.71dB
23-03-29 20:03:44.292 : --36-->    159.png | 17.41dB
23-03-29 20:03:44.611 : --37-->  15930.png | 21.53dB
23-03-29 20:03:44.935 : --38-->  16028.png | 18.86dB
23-03-29 20:03:45.245 : --39-->   1619.png | 14.55dB
23-03-29 20:03:45.552 : --40-->    168.png | 19.20dB
23-03-29 20:07:04.167 :   task: drunet
  model: plain
  gpu_ids: [0]
  scale: 1
  n_channels: 1
  n_channels_datasetload: 3
  sigma: [0, 50]
  sigma_test: 25
  path:[
    root: denoising
    pretrained_netG: None
    task: denoising/drunet
    log: denoising/drunet
    options: denoising/drunet/options
    models: denoising/drunet/models
    images: denoising/drunet/images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: ffdnet
      dataroot_H: trainsets/web_images_train
      num_patches_per_image: 10
      dataroot_L: trainsets/simulations
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 64
      phase: train
      scale: 1
      n_channels: 1
    ]
    test:[
      name: test_dataset
      dataset_type: ffdnet
      dataroot_H: testsets/web_images_test
      dataroot_L: testsets/simulations
      phase: test
      scale: 1
      n_channels: 1
    ]
  ]
  netG:[
    net_type: drunet
    in_nc: 1
    out_nc: 1
    nc: [64, 128, 256, 512]
    nb: 4
    gc: 32
    ng: 2
    reduction: 16
    act_mode: R
    upsample_mode: convtranspose
    downsample_mode: strideconv
    bias: False
    init_type: orthogonal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 1
  ]
  train:[
    epochs: 1000
    G_lossfn_type: tv
    G_lossfn_weight: 1.0
    G_tvloss_weight: 0.001
    G_optimizer_type: adam
    G_optimizer_lr: 0.0001
    G_optimizer_clipgrad: None
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [100000, 200000, 300000, 400000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    checkpoint_test: 400
    checkpoint_save: 800
    checkpoint_print: 16
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
    G_optimizer_wd: 0
    G_optimizer_reuse: False
    G_param_strict: True
    E_param_strict: True
    E_decay: 0
  ]
  opt_path: options/train_drunet.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

23-03-29 20:07:04.172 : Number of train images: 500, iters: 8
23-03-29 20:07:04.898 : 
Networks name: UNetRes
Params number: 32638080
Net structure:
UNetRes(
  (m_head): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (m_down1): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down2): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_down3): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2), bias=False)
  )
  (m_body): Sequential(
    (0): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up3): Sequential(
    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up2): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_up1): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
    (1): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (2): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (3): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (4): ResBlock(
      (res): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (m_tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
)

23-03-29 20:07:04.916 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.084 |  0.074 |  0.025 | torch.Size([64, 1, 3, 3]) || m_head.weight
 |  0.000 | -0.034 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.0.res.0.weight
 | -0.000 | -0.034 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.0.res.2.weight
 | -0.000 | -0.035 |  0.031 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.1.res.0.weight
 | -0.000 | -0.035 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.1.res.2.weight
 |  0.000 | -0.034 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.2.res.0.weight
 |  0.000 | -0.039 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.2.res.2.weight
 |  0.000 | -0.034 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.3.res.0.weight
 | -0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || m_down1.3.res.2.weight
 |  0.000 | -0.048 |  0.053 |  0.013 | torch.Size([128, 64, 2, 2]) || m_down1.4.weight
 | -0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.0.res.0.weight
 |  0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.0.res.2.weight
 | -0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.1.res.0.weight
 |  0.000 | -0.026 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.1.res.2.weight
 |  0.000 | -0.027 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.2.res.0.weight
 | -0.000 | -0.027 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.2.res.2.weight
 |  0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.3.res.0.weight
 | -0.000 | -0.025 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_down2.3.res.2.weight
 |  0.000 | -0.038 |  0.041 |  0.009 | torch.Size([256, 128, 2, 2]) || m_down2.4.weight
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.0.res.0.weight
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.0.res.2.weight
 |  0.000 | -0.020 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.1.res.0.weight
 | -0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.1.res.2.weight
 | -0.000 | -0.021 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.2.res.0.weight
 | -0.000 | -0.022 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.2.res.2.weight
 | -0.000 | -0.021 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.3.res.0.weight
 |  0.000 | -0.019 |  0.020 |  0.004 | torch.Size([256, 256, 3, 3]) || m_down3.3.res.2.weight
 | -0.000 | -0.031 |  0.031 |  0.006 | torch.Size([512, 256, 2, 2]) || m_down3.4.weight
 |  0.000 | -0.014 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.0.res.0.weight
 |  0.000 | -0.016 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.0.res.2.weight
 | -0.000 | -0.014 |  0.016 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.1.res.0.weight
 |  0.000 | -0.014 |  0.014 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.1.res.2.weight
 | -0.000 | -0.015 |  0.014 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.2.res.0.weight
 | -0.000 | -0.015 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.2.res.2.weight
 |  0.000 | -0.015 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.3.res.0.weight
 |  0.000 | -0.014 |  0.015 |  0.003 | torch.Size([512, 512, 3, 3]) || m_body.3.res.2.weight
 | -0.000 | -0.029 |  0.029 |  0.006 | torch.Size([512, 256, 2, 2]) || m_up3.0.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.1.res.0.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.1.res.2.weight
 | -0.000 | -0.018 |  0.018 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.2.res.0.weight
 |  0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.2.res.2.weight
 | -0.000 | -0.021 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.3.res.0.weight
 | -0.000 | -0.021 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.3.res.2.weight
 | -0.000 | -0.020 |  0.019 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.4.res.0.weight
 |  0.000 | -0.020 |  0.021 |  0.004 | torch.Size([256, 256, 3, 3]) || m_up3.4.res.2.weight
 |  0.000 | -0.037 |  0.043 |  0.009 | torch.Size([256, 128, 2, 2]) || m_up2.0.weight
 | -0.000 | -0.024 |  0.024 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.1.res.0.weight
 | -0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.1.res.2.weight
 |  0.000 | -0.026 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.2.res.0.weight
 | -0.000 | -0.025 |  0.029 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.2.res.2.weight
 |  0.000 | -0.025 |  0.025 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.3.res.0.weight
 |  0.000 | -0.025 |  0.026 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.3.res.2.weight
 |  0.000 | -0.025 |  0.028 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.4.res.0.weight
 |  0.000 | -0.027 |  0.027 |  0.006 | torch.Size([128, 128, 3, 3]) || m_up2.4.res.2.weight
 |  0.000 | -0.048 |  0.058 |  0.013 | torch.Size([128, 64, 2, 2]) || m_up1.0.weight
 |  0.000 | -0.037 |  0.036 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.1.res.0.weight
 | -0.000 | -0.037 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.1.res.2.weight
 |  0.000 | -0.033 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.2.res.0.weight
 |  0.000 | -0.035 |  0.033 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.2.res.2.weight
 | -0.000 | -0.032 |  0.035 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.3.res.0.weight
 | -0.000 | -0.036 |  0.030 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.3.res.2.weight
 |  0.000 | -0.034 |  0.032 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.4.res.0.weight
 |  0.000 | -0.038 |  0.034 |  0.008 | torch.Size([64, 64, 3, 3]) || m_up1.4.res.2.weight
 | -0.000 | -0.024 |  0.026 |  0.008 | torch.Size([1, 64, 3, 3]) || m_tail.weight

23-03-29 20:07:18.803 : <epoch:  2, iter:      16, lr:1.000e-04> G_loss: 6.172e-01 
23-03-29 20:07:31.094 : <epoch:  4, iter:      32, lr:1.000e-04> G_loss: 3.762e-01 
23-03-29 20:07:43.542 : <epoch:  6, iter:      48, lr:1.000e-04> G_loss: 1.091e-01 
23-03-29 20:07:57.374 : <epoch:  9, iter:      64, lr:1.000e-04> G_loss: 8.076e-02 
23-03-29 20:08:09.868 : <epoch: 11, iter:      80, lr:1.000e-04> G_loss: 7.345e-02 
23-03-29 20:08:22.394 : <epoch: 13, iter:      96, lr:1.000e-04> G_loss: 6.412e-02 
23-03-29 20:08:34.836 : <epoch: 15, iter:     112, lr:1.000e-04> G_loss: 5.182e-02 
23-03-29 20:08:48.823 : <epoch: 18, iter:     128, lr:1.000e-04> G_loss: 2.652e-02 
23-03-29 20:09:01.400 : <epoch: 20, iter:     144, lr:1.000e-04> G_loss: 2.291e-02 
23-03-29 20:09:14.044 : <epoch: 22, iter:     160, lr:1.000e-04> G_loss: 1.760e-02 
23-03-29 20:09:28.459 : <epoch: 25, iter:     176, lr:1.000e-04> G_loss: 1.809e-02 
23-03-29 20:09:41.441 : <epoch: 27, iter:     192, lr:1.000e-04> G_loss: 1.706e-02 
23-03-29 20:09:54.293 : <epoch: 29, iter:     208, lr:1.000e-04> G_loss: 1.425e-02 
23-03-29 20:10:07.526 : <epoch: 31, iter:     224, lr:1.000e-04> G_loss: 1.217e-02 
23-03-29 20:10:22.309 : <epoch: 34, iter:     240, lr:1.000e-04> G_loss: 9.582e-03 
23-03-29 20:10:35.476 : <epoch: 36, iter:     256, lr:1.000e-04> G_loss: 1.002e-02 
23-03-29 20:10:48.488 : <epoch: 38, iter:     272, lr:1.000e-04> G_loss: 9.785e-03 
23-03-29 20:11:03.564 : <epoch: 41, iter:     288, lr:1.000e-04> G_loss: 7.654e-03 
23-03-29 20:11:16.658 : <epoch: 43, iter:     304, lr:1.000e-04> G_loss: 8.512e-03 
23-03-29 20:11:29.842 : <epoch: 45, iter:     320, lr:1.000e-04> G_loss: 7.706e-03 
23-03-29 20:11:43.363 : <epoch: 47, iter:     336, lr:1.000e-04> G_loss: 9.458e-03 
23-03-29 20:11:58.586 : <epoch: 50, iter:     352, lr:1.000e-04> G_loss: 7.376e-03 
23-03-29 20:12:11.992 : <epoch: 52, iter:     368, lr:1.000e-04> G_loss: 7.943e-03 
23-03-29 20:12:25.665 : <epoch: 54, iter:     384, lr:1.000e-04> G_loss: 5.977e-03 
23-03-29 20:12:40.640 : <epoch: 57, iter:     400, lr:1.000e-04> G_loss: 7.038e-03 
23-03-29 20:12:41.085 : ---1-->  10094.png | 22.18dB
23-03-29 20:12:41.409 : ---2-->  10231.png | 22.58dB
23-03-29 20:12:41.729 : ---3-->   1037.png | 24.36dB
23-03-29 20:12:42.054 : ---4-->  10379.png | 23.55dB
23-03-29 20:12:42.396 : ---5-->  10420.png | 28.16dB
23-03-29 20:12:42.716 : ---6-->  10436.png | 24.39dB
23-03-29 20:12:43.039 : ---7-->  10534.png | 22.82dB
23-03-29 20:12:43.365 : ---8-->  11054.png | 23.86dB
23-03-29 20:12:43.700 : ---9-->  11143.png | 21.81dB
23-03-29 20:12:44.021 : --10-->  11294.png | 23.86dB
23-03-29 20:12:44.345 : --11-->  11404.png | 23.87dB
23-03-29 20:12:44.664 : --12-->  11604.png | 23.42dB
23-03-29 20:12:45.003 : --13-->  11708.png | 23.42dB
23-03-29 20:12:45.328 : --14-->  11712.png | 22.87dB
23-03-29 20:12:45.645 : --15-->  11880.png | 24.22dB
23-03-29 20:12:45.970 : --16-->   1190.png | 21.01dB
23-03-29 20:12:46.309 : --17-->  12009.png | 20.40dB
23-03-29 20:12:46.629 : --18-->  12248.png | 22.71dB
23-03-29 20:12:46.961 : --19-->  12449.png | 22.83dB
23-03-29 20:12:47.284 : --20-->  12460.png | 23.39dB
23-03-29 20:12:47.616 : --21-->    125.png | 24.04dB
23-03-29 20:12:47.942 : --22-->  12539.png | 23.91dB
23-03-29 20:12:48.266 : --23-->    134.png | 23.07dB
23-03-29 20:12:48.586 : --24-->  13450.png | 22.43dB
23-03-29 20:12:48.928 : --25-->  13902.png | 24.88dB
23-03-29 20:12:49.252 : --26-->  14107.png | 23.04dB
23-03-29 20:12:49.570 : --27-->   1421.png | 21.35dB
23-03-29 20:12:49.898 : --28-->  14305.png | 23.81dB
23-03-29 20:12:50.239 : --29-->   1431.png | 22.86dB
23-03-29 20:12:50.558 : --30-->  14926.png | 22.81dB
23-03-29 20:12:50.886 : --31-->  15307.png | 22.20dB
23-03-29 20:12:51.205 : --32-->  15387.png | 22.78dB
23-03-29 20:12:51.544 : --33-->  15612.png | 21.37dB
23-03-29 20:12:51.872 : --34-->  15661.png | 25.40dB
23-03-29 20:12:52.194 : --35-->  15681.png | 23.10dB
23-03-29 20:12:52.519 : --36-->    159.png | 20.86dB
23-03-29 20:12:52.856 : --37-->  15930.png | 24.81dB
23-03-29 20:12:53.177 : --38-->  16028.png | 23.34dB
23-03-29 20:12:53.502 : --39-->   1619.png | 20.06dB
23-03-29 20:12:53.834 : --40-->    168.png | 23.38dB
23-03-29 20:12:54.172 : --41-->    174.png | 23.65dB
23-03-29 20:12:54.500 : --42-->    188.png | 23.16dB
23-03-29 20:12:54.839 : --43-->   1928.png | 20.83dB
23-03-29 20:12:55.183 : --44-->   1942.png | 23.83dB
23-03-29 20:12:55.503 : --45-->    209.png | 22.72dB
23-03-29 20:12:55.831 : --46-->   2179.png | 24.00dB
23-03-29 20:12:56.154 : --47-->   2541.png | 23.00dB
23-03-29 20:12:56.499 : --48-->   3164.png | 22.30dB
23-03-29 20:12:56.828 : --49-->   3259.png | 21.61dB
23-03-29 20:12:57.146 : --50-->   3410.png | 23.17dB
23-03-29 20:12:57.164 : <epoch: 57, iter:     400, Average PSNR : 23.07dB

23-03-29 20:13:10.972 : <epoch: 59, iter:     416, lr:1.000e-04> G_loss: 5.832e-03 
23-03-29 20:13:24.676 : <epoch: 61, iter:     432, lr:1.000e-04> G_loss: 6.855e-03 
23-03-29 20:13:38.026 : <epoch: 63, iter:     448, lr:1.000e-04> G_loss: 5.609e-03 
23-03-29 20:13:53.702 : <epoch: 66, iter:     464, lr:1.000e-04> G_loss: 6.339e-03 
23-03-29 20:14:07.071 : <epoch: 68, iter:     480, lr:1.000e-04> G_loss: 6.584e-03 
23-03-29 20:14:20.664 : <epoch: 70, iter:     496, lr:1.000e-04> G_loss: 7.777e-03 
23-03-29 20:14:36.357 : <epoch: 73, iter:     512, lr:1.000e-04> G_loss: 6.232e-03 
23-03-29 20:14:49.742 : <epoch: 75, iter:     528, lr:1.000e-04> G_loss: 4.771e-03 
23-03-29 20:15:03.377 : <epoch: 77, iter:     544, lr:1.000e-04> G_loss: 6.122e-03 
23-03-29 20:15:16.929 : <epoch: 79, iter:     560, lr:1.000e-04> G_loss: 5.578e-03 
23-03-29 20:15:32.174 : <epoch: 82, iter:     576, lr:1.000e-04> G_loss: 6.812e-03 
23-03-29 20:15:46.096 : <epoch: 84, iter:     592, lr:1.000e-04> G_loss: 5.047e-03 
23-03-29 20:16:00.171 : <epoch: 86, iter:     608, lr:1.000e-04> G_loss: 4.470e-03 
23-03-29 20:16:15.420 : <epoch: 89, iter:     624, lr:1.000e-04> G_loss: 6.282e-03 
23-03-29 20:16:29.365 : <epoch: 91, iter:     640, lr:1.000e-04> G_loss: 4.289e-03 
23-03-29 20:16:43.474 : <epoch: 93, iter:     656, lr:1.000e-04> G_loss: 4.197e-03 
23-03-29 20:16:57.075 : <epoch: 95, iter:     672, lr:1.000e-04> G_loss: 6.215e-03 
23-03-29 20:17:12.759 : <epoch: 98, iter:     688, lr:1.000e-04> G_loss: 5.566e-03 
23-03-29 20:17:26.654 : <epoch:100, iter:     704, lr:1.000e-04> G_loss: 5.774e-03 
23-03-29 20:17:40.181 : <epoch:102, iter:     720, lr:1.000e-04> G_loss: 4.428e-03 
23-03-29 20:17:56.075 : <epoch:105, iter:     736, lr:1.000e-04> G_loss: 4.607e-03 
23-03-29 20:18:10.213 : <epoch:107, iter:     752, lr:1.000e-04> G_loss: 4.903e-03 
23-03-29 20:18:23.851 : <epoch:109, iter:     768, lr:1.000e-04> G_loss: 5.160e-03 
23-03-29 20:18:37.702 : <epoch:111, iter:     784, lr:1.000e-04> G_loss: 4.866e-03 
23-03-29 20:18:53.827 : <epoch:114, iter:     800, lr:1.000e-04> G_loss: 4.224e-03 
23-03-29 20:18:53.827 : Saving the model.
23-03-29 20:18:54.443 : ---1-->  10094.png | 24.82dB
23-03-29 20:18:54.776 : ---2-->  10231.png | 24.92dB
23-03-29 20:18:55.102 : ---3-->   1037.png | 26.80dB
23-03-29 20:18:55.457 : ---4-->  10379.png | 26.06dB
23-03-29 20:18:55.791 : ---5-->  10420.png | 29.49dB
23-03-29 20:18:56.123 : ---6-->  10436.png | 26.83dB
23-03-29 20:18:56.479 : ---7-->  10534.png | 25.26dB
23-03-29 20:18:56.815 : ---8-->  11054.png | 25.87dB
23-03-29 20:18:57.150 : ---9-->  11143.png | 24.69dB
23-03-29 20:18:57.504 : --10-->  11294.png | 26.09dB
23-03-29 20:18:57.843 : --11-->  11404.png | 27.19dB
23-03-29 20:18:58.178 : --12-->  11604.png | 25.90dB
23-03-29 20:18:58.534 : --13-->  11708.png | 25.94dB
23-03-29 20:18:58.872 : --14-->  11712.png | 25.48dB
23-03-29 20:18:59.206 : --15-->  11880.png | 25.72dB
23-03-29 20:18:59.558 : --16-->   1190.png | 23.60dB
23-03-29 20:18:59.902 : --17-->  12009.png | 22.94dB
23-03-29 20:19:00.233 : --18-->  12248.png | 24.84dB
23-03-29 20:19:00.579 : --19-->  12449.png | 25.30dB
23-03-29 20:19:00.918 : --20-->  12460.png | 26.20dB
23-03-29 20:19:01.261 : --21-->    125.png | 26.16dB
23-03-29 20:19:01.612 : --22-->  12539.png | 26.52dB
23-03-29 20:19:01.947 : --23-->    134.png | 26.03dB
23-03-29 20:19:02.282 : --24-->  13450.png | 25.04dB
23-03-29 20:19:02.631 : --25-->  13902.png | 27.74dB
23-03-29 20:19:02.969 : --26-->  14107.png | 25.65dB
23-03-29 20:19:03.303 : --27-->   1421.png | 23.97dB
23-03-29 20:19:03.654 : --28-->  14305.png | 26.28dB
23-03-29 20:19:03.992 : --29-->   1431.png | 25.73dB
23-03-29 20:19:04.324 : --30-->  14926.png | 25.34dB
23-03-29 20:19:04.672 : --31-->  15307.png | 24.21dB
23-03-29 20:19:05.015 : --32-->  15387.png | 25.81dB
23-03-29 20:19:05.365 : --33-->  15612.png | 23.78dB
23-03-29 20:19:05.722 : --34-->  15661.png | 27.73dB
23-03-29 20:19:06.065 : --35-->  15681.png | 25.60dB
23-03-29 20:19:06.402 : --36-->    159.png | 23.44dB
23-03-29 20:19:06.755 : --37-->  15930.png | 26.48dB
23-03-29 20:19:07.095 : --38-->  16028.png | 26.05dB
23-03-29 20:19:07.428 : --39-->   1619.png | 22.98dB
23-03-29 20:19:07.781 : --40-->    168.png | 25.96dB
23-03-29 20:19:08.122 : --41-->    174.png | 25.76dB
23-03-29 20:19:08.460 : --42-->    188.png | 25.85dB
23-03-29 20:19:08.820 : --43-->   1928.png | 22.92dB
23-03-29 20:19:09.162 : --44-->   1942.png | 27.01dB
23-03-29 20:19:09.497 : --45-->    209.png | 25.71dB
23-03-29 20:19:09.863 : --46-->   2179.png | 26.87dB
23-03-29 20:19:10.201 : --47-->   2541.png | 25.08dB
23-03-29 20:19:10.540 : --48-->   3164.png | 24.89dB
23-03-29 20:19:10.904 : --49-->   3259.png | 24.03dB
23-03-29 20:19:11.245 : --50-->   3410.png | 26.09dB
23-03-29 20:19:11.268 : <epoch:114, iter:     800, Average PSNR : 25.57dB

23-03-29 20:19:25.573 : <epoch:116, iter:     816, lr:1.000e-04> G_loss: 4.042e-03 
23-03-29 20:19:39.496 : <epoch:118, iter:     832, lr:1.000e-04> G_loss: 3.769e-03 
23-03-29 20:19:55.072 : <epoch:121, iter:     848, lr:1.000e-04> G_loss: 4.484e-03 
23-03-29 20:20:09.200 : <epoch:123, iter:     864, lr:1.000e-04> G_loss: 4.077e-03 
23-03-29 20:20:23.126 : <epoch:125, iter:     880, lr:1.000e-04> G_loss: 3.761e-03 
23-03-29 20:20:36.801 : <epoch:127, iter:     896, lr:1.000e-04> G_loss: 3.772e-03 
23-03-29 20:20:52.740 : <epoch:130, iter:     912, lr:1.000e-04> G_loss: 3.842e-03 
23-03-29 20:21:06.698 : <epoch:132, iter:     928, lr:1.000e-04> G_loss: 4.670e-03 
23-03-29 20:21:20.390 : <epoch:134, iter:     944, lr:1.000e-04> G_loss: 3.772e-03 
23-03-29 20:21:36.357 : <epoch:137, iter:     960, lr:1.000e-04> G_loss: 3.336e-03 
23-03-29 20:21:50.684 : <epoch:139, iter:     976, lr:1.000e-04> G_loss: 3.660e-03 
23-03-29 20:22:04.247 : <epoch:141, iter:     992, lr:1.000e-04> G_loss: 4.113e-03 
23-03-29 20:22:18.121 : <epoch:143, iter:   1,008, lr:1.000e-04> G_loss: 4.899e-03 
23-03-29 20:22:34.256 : <epoch:146, iter:   1,024, lr:1.000e-04> G_loss: 3.519e-03 
23-03-29 20:22:48.523 : <epoch:148, iter:   1,040, lr:1.000e-04> G_loss: 3.602e-03 
23-03-29 20:23:02.153 : <epoch:150, iter:   1,056, lr:1.000e-04> G_loss: 3.245e-03 
23-03-29 20:23:18.022 : <epoch:153, iter:   1,072, lr:1.000e-04> G_loss: 3.912e-03 
23-03-29 20:23:32.178 : <epoch:155, iter:   1,088, lr:1.000e-04> G_loss: 3.856e-03 
23-03-29 20:23:46.315 : <epoch:157, iter:   1,104, lr:1.000e-04> G_loss: 3.866e-03 
23-03-29 20:24:00.517 : <epoch:159, iter:   1,120, lr:1.000e-04> G_loss: 3.854e-03 
23-03-29 20:24:16.325 : <epoch:162, iter:   1,136, lr:1.000e-04> G_loss: 3.562e-03 
23-03-29 20:24:30.053 : <epoch:164, iter:   1,152, lr:1.000e-04> G_loss: 2.920e-03 
23-03-29 20:24:44.156 : <epoch:166, iter:   1,168, lr:1.000e-04> G_loss: 3.403e-03 
23-03-29 20:24:59.849 : <epoch:169, iter:   1,184, lr:1.000e-04> G_loss: 3.555e-03 
23-03-29 20:25:13.664 : <epoch:171, iter:   1,200, lr:1.000e-04> G_loss: 2.904e-03 
23-03-29 20:25:14.133 : ---1-->  10094.png | 26.57dB
23-03-29 20:25:14.464 : ---2-->  10231.png | 27.52dB
23-03-29 20:25:14.787 : ---3-->   1037.png | 28.61dB
23-03-29 20:25:15.126 : ---4-->  10379.png | 27.97dB
23-03-29 20:25:15.459 : ---5-->  10420.png | 30.03dB
23-03-29 20:25:15.789 : ---6-->  10436.png | 28.92dB
23-03-29 20:25:16.139 : ---7-->  10534.png | 26.52dB
23-03-29 20:25:16.465 : ---8-->  11054.png | 28.22dB
23-03-29 20:25:16.798 : ---9-->  11143.png | 26.80dB
23-03-29 20:25:17.138 : --10-->  11294.png | 28.65dB
23-03-29 20:25:17.474 : --11-->  11404.png | 29.18dB
23-03-29 20:25:17.810 : --12-->  11604.png | 27.69dB
23-03-29 20:25:18.149 : --13-->  11708.png | 27.82dB
23-03-29 20:25:18.485 : --14-->  11712.png | 27.65dB
23-03-29 20:25:18.823 : --15-->  11880.png | 26.56dB
23-03-29 20:25:19.159 : --16-->   1190.png | 26.26dB
23-03-29 20:25:19.496 : --17-->  12009.png | 25.55dB
23-03-29 20:25:19.833 : --18-->  12248.png | 26.82dB
23-03-29 20:25:20.170 : --19-->  12449.png | 26.83dB
23-03-29 20:25:20.501 : --20-->  12460.png | 28.08dB
23-03-29 20:25:20.839 : --21-->    125.png | 27.88dB
23-03-29 20:25:21.177 : --22-->  12539.png | 28.68dB
23-03-29 20:25:21.507 : --23-->    134.png | 28.78dB
23-03-29 20:25:21.843 : --24-->  13450.png | 27.28dB
23-03-29 20:25:22.187 : --25-->  13902.png | 29.47dB
23-03-29 20:25:22.519 : --26-->  14107.png | 28.19dB
23-03-29 20:25:22.852 : --27-->   1421.png | 26.44dB
23-03-29 20:25:23.197 : --28-->  14305.png | 27.81dB
23-03-29 20:25:23.528 : --29-->   1431.png | 28.33dB
23-03-29 20:25:23.860 : --30-->  14926.png | 26.90dB
23-03-29 20:25:24.207 : --31-->  15307.png | 25.97dB
23-03-29 20:25:24.537 : --32-->  15387.png | 27.98dB
23-03-29 20:25:24.871 : --33-->  15612.png | 25.78dB
23-03-29 20:25:25.220 : --34-->  15661.png | 30.15dB
23-03-29 20:25:25.556 : --35-->  15681.png | 27.70dB
23-03-29 20:25:25.887 : --36-->    159.png | 25.92dB
23-03-29 20:25:26.236 : --37-->  15930.png | 28.11dB
23-03-29 20:25:26.571 : --38-->  16028.png | 28.17dB
23-03-29 20:25:26.910 : --39-->   1619.png | 24.43dB
23-03-29 20:25:27.265 : --40-->    168.png | 27.14dB
23-03-29 20:25:27.598 : --41-->    174.png | 27.42dB
23-03-29 20:25:27.925 : --42-->    188.png | 28.89dB
23-03-29 20:25:28.283 : --43-->   1928.png | 25.32dB
23-03-29 20:25:28.619 : --44-->   1942.png | 28.89dB
23-03-29 20:25:28.944 : --45-->    209.png | 28.33dB
23-03-29 20:25:29.291 : --46-->   2179.png | 28.73dB
23-03-29 20:25:29.624 : --47-->   2541.png | 27.03dB
23-03-29 20:25:29.958 : --48-->   3164.png | 27.01dB
23-03-29 20:25:30.304 : --49-->   3259.png | 26.09dB
23-03-29 20:25:30.630 : --50-->   3410.png | 28.25dB
23-03-29 20:25:30.653 : <epoch:171, iter:   1,200, Average PSNR : 27.59dB

23-03-29 20:25:45.205 : <epoch:173, iter:   1,216, lr:1.000e-04> G_loss: 3.559e-03 
23-03-29 20:25:58.952 : <epoch:175, iter:   1,232, lr:1.000e-04> G_loss: 3.455e-03 
23-03-29 20:26:14.973 : <epoch:178, iter:   1,248, lr:1.000e-04> G_loss: 2.824e-03 
23-03-29 20:26:29.293 : <epoch:180, iter:   1,264, lr:1.000e-04> G_loss: 2.867e-03 
23-03-29 20:26:43.223 : <epoch:182, iter:   1,280, lr:1.000e-04> G_loss: 2.988e-03 
23-03-29 20:26:58.747 : <epoch:185, iter:   1,296, lr:1.000e-04> G_loss: 2.871e-03 
23-03-29 20:27:12.975 : <epoch:187, iter:   1,312, lr:1.000e-04> G_loss: 2.552e-03 
23-03-29 20:27:27.222 : <epoch:189, iter:   1,328, lr:1.000e-04> G_loss: 2.808e-03 
23-03-29 20:27:41.098 : <epoch:191, iter:   1,344, lr:1.000e-04> G_loss: 2.801e-03 
23-03-29 20:27:56.475 : <epoch:194, iter:   1,360, lr:1.000e-04> G_loss: 2.864e-03 
23-03-29 20:28:10.599 : <epoch:196, iter:   1,376, lr:1.000e-04> G_loss: 2.925e-03 
23-03-29 20:28:24.583 : <epoch:198, iter:   1,392, lr:1.000e-04> G_loss: 3.121e-03 
23-03-29 20:28:40.068 : <epoch:201, iter:   1,408, lr:1.000e-04> G_loss: 3.202e-03 
23-03-29 20:28:54.334 : <epoch:203, iter:   1,424, lr:1.000e-04> G_loss: 3.163e-03 
23-03-29 20:29:08.678 : <epoch:205, iter:   1,440, lr:1.000e-04> G_loss: 2.412e-03 
23-03-29 20:29:22.310 : <epoch:207, iter:   1,456, lr:1.000e-04> G_loss: 3.433e-03 
23-03-29 20:29:38.057 : <epoch:210, iter:   1,472, lr:1.000e-04> G_loss: 2.782e-03 
23-03-29 20:29:52.437 : <epoch:212, iter:   1,488, lr:1.000e-04> G_loss: 3.161e-03 
23-03-29 20:30:06.529 : <epoch:214, iter:   1,504, lr:1.000e-04> G_loss: 2.950e-03 
23-03-29 20:30:21.990 : <epoch:217, iter:   1,520, lr:1.000e-04> G_loss: 3.260e-03 
23-03-29 20:30:36.176 : <epoch:219, iter:   1,536, lr:1.000e-04> G_loss: 2.731e-03 
23-03-29 20:30:50.368 : <epoch:221, iter:   1,552, lr:1.000e-04> G_loss: 3.039e-03 
23-03-29 20:31:04.624 : <epoch:223, iter:   1,568, lr:1.000e-04> G_loss: 2.530e-03 
23-03-29 20:31:20.780 : <epoch:226, iter:   1,584, lr:1.000e-04> G_loss: 2.386e-03 
23-03-29 20:31:34.378 : <epoch:228, iter:   1,600, lr:1.000e-04> G_loss: 2.765e-03 
23-03-29 20:31:34.379 : Saving the model.
23-03-29 20:31:34.978 : ---1-->  10094.png | 27.02dB
23-03-29 20:31:35.315 : ---2-->  10231.png | 28.10dB
23-03-29 20:31:35.651 : ---3-->   1037.png | 28.94dB
23-03-29 20:31:36.003 : ---4-->  10379.png | 28.38dB
23-03-29 20:31:36.343 : ---5-->  10420.png | 30.50dB
23-03-29 20:31:36.677 : ---6-->  10436.png | 29.32dB
23-03-29 20:31:37.026 : ---7-->  10534.png | 27.23dB
23-03-29 20:31:37.369 : ---8-->  11054.png | 29.01dB
23-03-29 20:31:37.708 : ---9-->  11143.png | 27.39dB
23-03-29 20:31:38.057 : --10-->  11294.png | 29.06dB
23-03-29 20:31:38.398 : --11-->  11404.png | 29.67dB
23-03-29 20:31:38.739 : --12-->  11604.png | 28.03dB
23-03-29 20:31:39.088 : --13-->  11708.png | 28.16dB
23-03-29 20:31:39.421 : --14-->  11712.png | 28.07dB
23-03-29 20:31:39.755 : --15-->  11880.png | 26.81dB
23-03-29 20:31:40.108 : --16-->   1190.png | 26.96dB
23-03-29 20:31:40.448 : --17-->  12009.png | 26.31dB
23-03-29 20:31:40.788 : --18-->  12248.png | 27.18dB
23-03-29 20:31:41.137 : --19-->  12449.png | 27.32dB
23-03-29 20:31:41.477 : --20-->  12460.png | 28.38dB
23-03-29 20:31:41.823 : --21-->    125.png | 28.29dB
23-03-29 20:31:42.173 : --22-->  12539.png | 29.35dB
23-03-29 20:31:42.506 : --23-->    134.png | 29.35dB
23-03-29 20:31:42.847 : --24-->  13450.png | 27.75dB
23-03-29 20:31:43.208 : --25-->  13902.png | 30.08dB
23-03-29 20:31:43.534 : --26-->  14107.png | 28.83dB
23-03-29 20:31:43.872 : --27-->   1421.png | 27.13dB
23-03-29 20:31:44.234 : --28-->  14305.png | 27.99dB
23-03-29 20:31:44.563 : --29-->   1431.png | 28.81dB
23-03-29 20:31:44.905 : --30-->  14926.png | 27.27dB
23-03-29 20:31:45.267 : --31-->  15307.png | 26.41dB
23-03-29 20:31:45.593 : --32-->  15387.png | 28.47dB
23-03-29 20:31:45.929 : --33-->  15612.png | 26.29dB
23-03-29 20:31:46.293 : --34-->  15661.png | 30.32dB
23-03-29 20:31:46.618 : --35-->  15681.png | 28.25dB
23-03-29 20:31:46.959 : --36-->    159.png | 26.59dB
23-03-29 20:31:47.327 : --37-->  15930.png | 28.43dB
23-03-29 20:31:47.658 : --38-->  16028.png | 28.82dB
23-03-29 20:31:48.006 : --39-->   1619.png | 25.09dB
23-03-29 20:31:48.369 : --40-->    168.png | 27.75dB
23-03-29 20:31:48.708 : --41-->    174.png | 27.90dB
23-03-29 20:31:49.054 : --42-->    188.png | 29.33dB
23-03-29 20:31:49.419 : --43-->   1928.png | 26.42dB
23-03-29 20:31:49.761 : --44-->   1942.png | 29.52dB
23-03-29 20:31:50.086 : --45-->    209.png | 28.86dB
23-03-29 20:31:50.443 : --46-->   2179.png | 29.15dB
23-03-29 20:31:50.790 : --47-->   2541.png | 27.39dB
23-03-29 20:31:51.117 : --48-->   3164.png | 27.56dB
23-03-29 20:31:51.471 : --49-->   3259.png | 26.61dB
23-03-29 20:31:51.820 : --50-->   3410.png | 28.75dB
23-03-29 20:31:51.843 : <epoch:228, iter:   1,600, Average PSNR : 28.09dB

23-03-29 20:32:06.098 : <epoch:230, iter:   1,616, lr:1.000e-04> G_loss: 3.086e-03 
23-03-29 20:32:22.352 : <epoch:233, iter:   1,632, lr:1.000e-04> G_loss: 2.581e-03 
23-03-29 20:32:36.121 : <epoch:235, iter:   1,648, lr:1.000e-04> G_loss: 2.600e-03 
23-03-29 20:32:50.196 : <epoch:237, iter:   1,664, lr:1.000e-04> G_loss: 2.915e-03 
23-03-29 20:33:04.498 : <epoch:239, iter:   1,680, lr:1.000e-04> G_loss: 2.373e-03 
23-03-29 20:33:20.170 : <epoch:242, iter:   1,696, lr:1.000e-04> G_loss: 2.562e-03 
23-03-29 20:33:34.076 : <epoch:244, iter:   1,712, lr:1.000e-04> G_loss: 2.413e-03 
23-03-29 20:33:48.244 : <epoch:246, iter:   1,728, lr:1.000e-04> G_loss: 2.624e-03 
23-03-29 20:34:03.864 : <epoch:249, iter:   1,744, lr:1.000e-04> G_loss: 2.933e-03 
23-03-29 20:34:17.562 : <epoch:251, iter:   1,760, lr:1.000e-04> G_loss: 2.344e-03 
23-03-29 20:34:31.635 : <epoch:253, iter:   1,776, lr:1.000e-04> G_loss: 2.569e-03 
23-03-29 20:34:46.090 : <epoch:255, iter:   1,792, lr:1.000e-04> G_loss: 3.064e-03 
23-03-29 20:35:01.453 : <epoch:258, iter:   1,808, lr:1.000e-04> G_loss: 2.184e-03 
23-03-29 20:35:15.596 : <epoch:260, iter:   1,824, lr:1.000e-04> G_loss: 2.568e-03 
23-03-29 20:35:29.926 : <epoch:262, iter:   1,840, lr:1.000e-04> G_loss: 2.814e-03 
23-03-29 20:35:45.573 : <epoch:265, iter:   1,856, lr:1.000e-04> G_loss: 3.246e-03 
23-03-29 20:35:59.487 : <epoch:267, iter:   1,872, lr:1.000e-04> G_loss: 2.374e-03 
23-03-29 20:36:13.724 : <epoch:269, iter:   1,888, lr:1.000e-04> G_loss: 2.795e-03 
23-03-29 20:36:28.007 : <epoch:271, iter:   1,904, lr:1.000e-04> G_loss: 2.037e-03 
23-03-29 20:36:43.625 : <epoch:274, iter:   1,920, lr:1.000e-04> G_loss: 2.533e-03 
23-03-29 20:36:57.551 : <epoch:276, iter:   1,936, lr:1.000e-04> G_loss: 1.959e-03 
23-03-29 20:37:11.911 : <epoch:278, iter:   1,952, lr:1.000e-04> G_loss: 2.506e-03 
23-03-29 20:37:27.640 : <epoch:281, iter:   1,968, lr:1.000e-04> G_loss: 1.936e-03 
23-03-29 20:37:41.365 : <epoch:283, iter:   1,984, lr:1.000e-04> G_loss: 2.803e-03 
23-03-29 20:37:55.511 : <epoch:285, iter:   2,000, lr:1.000e-04> G_loss: 2.317e-03 
23-03-29 20:37:55.985 : ---1-->  10094.png | 27.74dB
23-03-29 20:37:56.319 : ---2-->  10231.png | 29.51dB
23-03-29 20:37:56.649 : ---3-->   1037.png | 29.98dB
23-03-29 20:37:57.005 : ---4-->  10379.png | 29.61dB
23-03-29 20:37:57.341 : ---5-->  10420.png | 31.45dB
23-03-29 20:37:57.680 : ---6-->  10436.png | 30.64dB
23-03-29 20:37:58.038 : ---7-->  10534.png | 28.61dB
23-03-29 20:37:58.376 : ---8-->  11054.png | 30.47dB
23-03-29 20:37:58.709 : ---9-->  11143.png | 28.62dB
23-03-29 20:37:59.067 : --10-->  11294.png | 30.34dB
23-03-29 20:37:59.404 : --11-->  11404.png | 30.95dB
23-03-29 20:37:59.732 : --12-->  11604.png | 29.23dB
23-03-29 20:38:00.088 : --13-->  11708.png | 29.23dB
23-03-29 20:38:00.429 : --14-->  11712.png | 29.23dB
23-03-29 20:38:00.754 : --15-->  11880.png | 27.57dB
23-03-29 20:38:01.101 : --16-->   1190.png | 28.41dB
23-03-29 20:38:01.442 : --17-->  12009.png | 27.56dB
23-03-29 20:38:01.772 : --18-->  12248.png | 28.30dB
23-03-29 20:38:02.128 : --19-->  12449.png | 28.26dB
23-03-29 20:38:02.470 : --20-->  12460.png | 29.32dB
23-03-29 20:38:02.806 : --21-->    125.png | 29.50dB
23-03-29 20:38:03.162 : --22-->  12539.png | 30.84dB
23-03-29 20:38:03.502 : --23-->    134.png | 30.74dB
23-03-29 20:38:03.837 : --24-->  13450.png | 28.90dB
23-03-29 20:38:04.189 : --25-->  13902.png | 31.34dB
23-03-29 20:38:04.532 : --26-->  14107.png | 30.21dB
23-03-29 20:38:04.865 : --27-->   1421.png | 28.42dB
23-03-29 20:38:05.219 : --28-->  14305.png | 29.75dB
23-03-29 20:38:05.572 : --29-->   1431.png | 29.94dB
23-03-29 20:38:05.918 : --30-->  14926.png | 28.49dB
23-03-29 20:38:06.273 : --31-->  15307.png | 27.52dB
23-03-29 20:38:06.619 : --32-->  15387.png | 29.64dB
23-03-29 20:38:06.964 : --33-->  15612.png | 27.34dB
23-03-29 20:38:07.318 : --34-->  15661.png | 31.65dB
23-03-29 20:38:07.661 : --35-->  15681.png | 29.76dB
23-03-29 20:38:08.007 : --36-->    159.png | 27.91dB
23-03-29 20:38:08.356 : --37-->  15930.png | 29.56dB
23-03-29 20:38:08.688 : --38-->  16028.png | 30.12dB
23-03-29 20:38:09.041 : --39-->   1619.png | 26.26dB
23-03-29 20:38:09.388 : --40-->    168.png | 28.61dB
23-03-29 20:38:09.719 : --41-->    174.png | 29.08dB
23-03-29 20:38:10.071 : --42-->    188.png | 30.64dB
23-03-29 20:38:10.429 : --43-->   1928.png | 27.48dB
23-03-29 20:38:10.772 : --44-->   1942.png | 30.82dB
23-03-29 20:38:11.119 : --45-->    209.png | 30.05dB
23-03-29 20:38:11.478 : --46-->   2179.png | 30.65dB
23-03-29 20:38:11.811 : --47-->   2541.png | 28.31dB
23-03-29 20:38:12.145 : --48-->   3164.png | 28.82dB
23-03-29 20:38:12.508 : --49-->   3259.png | 27.77dB
23-03-29 20:38:12.850 : --50-->   3410.png | 29.89dB
23-03-29 20:38:12.873 : <epoch:285, iter:   2,000, Average PSNR : 29.30dB

23-03-29 20:38:27.229 : <epoch:287, iter:   2,016, lr:1.000e-04> G_loss: 1.925e-03 
23-03-29 20:38:42.808 : <epoch:290, iter:   2,032, lr:1.000e-04> G_loss: 2.143e-03 
23-03-29 20:38:56.783 : <epoch:292, iter:   2,048, lr:1.000e-04> G_loss: 2.565e-03 
23-03-29 20:39:11.104 : <epoch:294, iter:   2,064, lr:1.000e-04> G_loss: 2.571e-03 
23-03-29 20:39:27.191 : <epoch:297, iter:   2,080, lr:1.000e-04> G_loss: 2.436e-03 
23-03-29 20:39:40.870 : <epoch:299, iter:   2,096, lr:1.000e-04> G_loss: 2.636e-03 
23-03-29 20:39:55.076 : <epoch:301, iter:   2,112, lr:1.000e-04> G_loss: 2.438e-03 
23-03-29 20:40:09.409 : <epoch:303, iter:   2,128, lr:1.000e-04> G_loss: 2.121e-03 
23-03-29 20:40:25.536 : <epoch:306, iter:   2,144, lr:1.000e-04> G_loss: 1.990e-03 
23-03-29 20:40:38.828 : <epoch:308, iter:   2,160, lr:1.000e-04> G_loss: 3.049e-03 
23-03-29 20:40:52.578 : <epoch:310, iter:   2,176, lr:1.000e-04> G_loss: 2.143e-03 
23-03-29 20:41:08.708 : <epoch:313, iter:   2,192, lr:1.000e-04> G_loss: 2.496e-03 
23-03-29 20:41:23.023 : <epoch:315, iter:   2,208, lr:1.000e-04> G_loss: 2.162e-03 
23-03-29 20:41:37.089 : <epoch:317, iter:   2,224, lr:1.000e-04> G_loss: 2.673e-03 
23-03-29 20:41:50.768 : <epoch:319, iter:   2,240, lr:1.000e-04> G_loss: 2.845e-03 
23-03-29 20:42:06.989 : <epoch:322, iter:   2,256, lr:1.000e-04> G_loss: 1.779e-03 
23-03-29 20:42:21.090 : <epoch:324, iter:   2,272, lr:1.000e-04> G_loss: 2.617e-03 
23-03-29 20:42:35.219 : <epoch:326, iter:   2,288, lr:1.000e-04> G_loss: 2.532e-03 
23-03-29 20:42:52.957 : <epoch:329, iter:   2,304, lr:1.000e-04> G_loss: 2.566e-03 
23-03-29 20:43:09.010 : <epoch:331, iter:   2,320, lr:1.000e-04> G_loss: 1.840e-03 
23-03-29 20:43:25.073 : <epoch:333, iter:   2,336, lr:1.000e-04> G_loss: 2.544e-03 
23-03-29 20:43:41.243 : <epoch:335, iter:   2,352, lr:1.000e-04> G_loss: 2.149e-03 
23-03-29 20:43:59.349 : <epoch:338, iter:   2,368, lr:1.000e-04> G_loss: 2.129e-03 
23-03-29 20:44:15.512 : <epoch:340, iter:   2,384, lr:1.000e-04> G_loss: 2.182e-03 
23-03-29 20:44:31.566 : <epoch:342, iter:   2,400, lr:1.000e-04> G_loss: 2.190e-03 
23-03-29 20:44:31.566 : Saving the model.
23-03-29 20:44:32.255 : ---1-->  10094.png | 27.43dB
23-03-29 20:44:32.626 : ---2-->  10231.png | 29.63dB
23-03-29 20:44:32.991 : ---3-->   1037.png | 30.01dB
23-03-29 20:44:33.380 : ---4-->  10379.png | 29.66dB
23-03-29 20:44:33.763 : ---5-->  10420.png | 30.80dB
23-03-29 20:44:34.143 : ---6-->  10436.png | 30.73dB
23-03-29 20:44:34.556 : ---7-->  10534.png | 28.58dB
23-03-29 20:44:34.941 : ---8-->  11054.png | 30.07dB
23-03-29 20:44:35.327 : ---9-->  11143.png | 28.76dB
23-03-29 20:44:35.722 : --10-->  11294.png | 30.55dB
23-03-29 20:44:36.098 : --11-->  11404.png | 31.06dB
23-03-29 20:44:36.470 : --12-->  11604.png | 29.44dB
23-03-29 20:44:36.871 : --13-->  11708.png | 29.14dB
23-03-29 20:44:37.258 : --14-->  11712.png | 29.19dB
23-03-29 20:44:37.652 : --15-->  11880.png | 27.54dB
23-03-29 20:44:38.057 : --16-->   1190.png | 28.85dB
23-03-29 20:44:38.449 : --17-->  12009.png | 27.80dB
23-03-29 20:44:38.834 : --18-->  12248.png | 28.32dB
23-03-29 20:44:39.242 : --19-->  12449.png | 28.21dB
23-03-29 20:44:39.604 : --20-->  12460.png | 29.15dB
23-03-29 20:44:39.971 : --21-->    125.png | 29.51dB
23-03-29 20:44:40.373 : --22-->  12539.png | 30.50dB
23-03-29 20:44:40.752 : --23-->    134.png | 30.84dB
23-03-29 20:44:41.138 : --24-->  13450.png | 28.94dB
23-03-29 20:44:41.547 : --25-->  13902.png | 30.97dB
23-03-29 20:44:41.931 : --26-->  14107.png | 30.22dB
23-03-29 20:44:42.313 : --27-->   1421.png | 28.57dB
23-03-29 20:44:42.715 : --28-->  14305.png | 30.26dB
23-03-29 20:44:43.095 : --29-->   1431.png | 30.03dB
23-03-29 20:44:43.462 : --30-->  14926.png | 28.30dB
23-03-29 20:44:43.848 : --31-->  15307.png | 27.66dB
23-03-29 20:44:44.227 : --32-->  15387.png | 29.94dB
23-03-29 20:44:44.614 : --33-->  15612.png | 27.36dB
23-03-29 20:44:45.013 : --34-->  15661.png | 31.95dB
23-03-29 20:44:45.399 : --35-->  15681.png | 29.60dB
23-03-29 20:44:45.780 : --36-->    159.png | 28.09dB
23-03-29 20:44:46.186 : --37-->  15930.png | 29.43dB
23-03-29 20:44:46.574 : --38-->  16028.png | 30.12dB
23-03-29 20:44:46.943 : --39-->   1619.png | 26.14dB
23-03-29 20:44:47.329 : --40-->    168.png | 28.84dB
23-03-29 20:44:47.704 : --41-->    174.png | 29.09dB
23-03-29 20:44:48.084 : --42-->    188.png | 30.73dB
23-03-29 20:44:48.478 : --43-->   1928.png | 27.07dB
23-03-29 20:44:48.841 : --44-->   1942.png | 30.53dB
23-03-29 20:44:49.208 : --45-->    209.png | 30.03dB
23-03-29 20:44:49.606 : --46-->   2179.png | 30.83dB
23-03-29 20:44:49.976 : --47-->   2541.png | 28.24dB
23-03-29 20:44:50.357 : --48-->   3164.png | 29.05dB
23-03-29 20:44:50.759 : --49-->   3259.png | 27.90dB
23-03-29 20:44:51.144 : --50-->   3410.png | 30.01dB
23-03-29 20:44:51.163 : <epoch:342, iter:   2,400, Average PSNR : 29.31dB

